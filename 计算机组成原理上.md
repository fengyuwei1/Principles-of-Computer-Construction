# 计算机组成原理(上)

## 第一章 计算机系统概论

### 1.计算机系统简介

现代计算机系统由硬件和软件两部分组成。

硬件包括计算机的实体部分，如主机、外设等。

软件是由具有各类特殊功能的信息组成，通过软件来发挥硬件的作用。

计算机的系统软件包括语言处理程序、操作系统、数学库、MPI等。而应用软件则是面向特定任务和目标的程序，如游戏、数据库管理系统等。

计算机的算力的单位是Flops(floating point operations per second)，即每秒可执行的浮点运算次数，Flops并不能反应许多对实际输出运算效率有影响的因素，因而计算机的实际Flops算力与理论峰值会有一段不小的差距

### 2.计算机系统的层次结构

```markdown
高级语言   虚拟机器M3
汇编语言   虚拟机器M2
操作系统   虚拟机器
机器语言   实际机器M1
微指令系统 微程序机器M0
```

**高级语言**（如C、Python）：为程序员提供易于理解和操作的编程环境。

**汇编语言**：与机器语言对应，但采用了易于理解的符号表示。

**操作系统**：为硬件提供抽象层次，控制硬件资源并管理程序运行。

**机器语言**：计算机能直接理解的指令集，依赖于特定硬件架构。

**微指令系统**：底层硬件通过微指令来执行高层的指令集。

计算机系统结构定义了计算机系统的软硬件的交界面，程序员所看到的计算机系统的属性。计算机组成设计人员的任务是实现计算机体系结构所体现出来的属性。

### 3.计算机的基本组成

冯诺依曼计算机是一种**存储程序结构**的计算机，数据和程序以**二进制方式**存放在计算机中。冯诺依曼计算机由五大部件组成，包括**运算器、控制器、存储器、输入设备和输出设备**。指令和数据以**同等地位**保存在存储器中，以二进制形式表示。指令由**操作码和地址码**构成，操作码指明操作类型，地址码指明操作数所在地址。冯诺依曼计算机的核心特点是存储程序，程序存放在存储器中。冯诺依曼计算机的硬件框图以运算器为中心，数据通过运算器进行流动。然而，以运算器为核心的冯诺依曼结构存在繁忙和瓶颈问题。

冯诺依曼计算机由以下五大部件组成：

- **运算器（ALU）**：执行算术和逻辑运算。
- **控制器（CU）**：控制计算机各个部件的工作流程。
- **存储器**：存储程序和数据。
- **输入设备**：用于向计算机提供外部数据（如键盘、鼠标）。
- **输出设备**：用于从计算机获取处理结果（如显示器、打印机）。

冯诺依曼计算机的关键是**存储程序**，即程序作为数据存储在计算机中，通过控制器逐步执行指令。这种结构具有灵活性，但也存在性能瓶颈，主要体现在**冯诺依曼瓶颈**（即CPU与内存之间的数据传输速度差异）。

冯诺依曼机工作方式的基本特点是按地址访问并顺序执行指令。

**1.程序指令和数据共用同一个存储器，进行等位存储，可以按地址寻访**

**2.指令和数据均以二进制表示**

**3.指令由操作码和地址码组成**，操作码反应了该指令的具体操作，地址码反映了操作需要应用到的操作数据所在的地址

**4.对程序指令进行存储和读取执行**

**5.以运算器为运行中心**

**哈佛结构**是计算机体系的另一种组织结构，它与冯·诺伊曼结构最大的区别是区分了程序指令和数据的存储器，分别使用两套地址/数据总线进行读写，**改进型哈佛结构**则对地址/数据总线进行了统一

### 4.对冯诺依曼机进行改进

首先，我们将运算器作为中心改进为以存储器为中心的机器，实现了输入输出设备和存储器之间的直接信息交换。

计算机系统的层次化结构，将计算机硬件划分为主机系统和IO系统，并进一步细化了CPU、主存和IO设备等模块。

CPU：运算器ALU,控制器CU

存储器：主存，辅存

主机：主存，CPU

IO系统：输入设备，输出设备，辅存

应对系统复杂性的三种方法：层次化、模块化和规则性。

层次化：将被设置的系统划分为多个模块或子模块

模块化：有明确定义的功能和接口

规则性：模块更容易被重用

### 5.计算机可计算性理论

可计算性：一类问题能否使用计算机去解决。

程序：运算的全部步骤

指令：每一个步骤

在计算机中，**指令**和**数据**都保存在存储器中，程序通过操作存储器中的数据来进行计算。

### 6.存储器的基本组成

存储器由存储单元、存储字和存储原件组成，可以按地址进行寻址。

存储器是核心结构，由多个存储单元构成，每个存储单元保存了若干个01的个数，称为存储字。

存储字长是存储单元当中二进制代码的位数。

存储单元：存储器中的最小单位，每个存储单元可以存储一定量的数据（如一个字节）。

存储字：存储单元中二进制代码的组合，是存储器的基本访问单位。

存储单元按地址进行寻址，寄存器MAR(存储器地址寄存器)保存了存储单元的地址或编号，MAR反映了存储单元的个数。MDR(存储器数据寄存器)保存了要送入CPU中的数据或要保存到存储体中的数据，MDR反映了存储字长。

存储原件：用于存储数据的物理器件，如动态随机存储器（DRAM）和静态随机存储器（SRAM）。

MAR和MDR是**存储器联系外部的窗口**，或称**接口寄存器**

### 7.运算器的结构

运算器的核心结构是累加器(ACC)，保存了其中的一个操作数和运算的结果。

运算器的核心是算术逻辑运算单元(ALU)，它完成加、减、乘、除和与非等运算。

运算器的输入数据保存在寄存器中，其中ACC和X寄存器用于保存运算的数据，MQ寄存器用于保存乘法运算的结果。

| 运算 | ACC         | MQ            | X      |
| :--- | :---------- | :------------ | :----- |
| 加法 | 被加数 和   |               | 加数   |
| 减法 | 被减数 差   |               | 减数   |
| 乘法 | 乘积高位    | 乘数 乘积低位 | 被乘数 |
| 除法 | 被除数 余数 | 商            | 除数   |

**乘法操作通过累加和移位实现**

基本原理：

1. **分解乘数**：将乘数（乘法运算中的第二个操作数）分解为二进制形式。例如，如果乘数是13，其二进制表示为1101。
2. **累加**：对于乘数的每一位，如果该位是1，则将被乘数（乘法运算中的第一个操作数）累加到一个临时的累加器中。如果该位是0，则不进行累加。
3. **移位**：在每次累加之后，将累加器中的结果左移一位。这相当于将当前的累加结果乘以2。这样做的原因是，每次移位都是在模拟乘以2的操作，因为乘数的每一位都代表了一个2的幂次。
4. **重复操作**：重复上述累加和移位操作，直到处理完乘数的所有位。
5. **得到结果**：完成所有位的处理后，累加器中的结果就是原始被乘数与乘数的乘积。

示例：

如果我们计算 5×13：

- 13的二进制是1101。
- 首先，5（被乘数）乘以1，结果是5，累加器现在是5。
- 然后，将累加器左移一位，变成10。
- 接着，5乘以1，累加，累加器保持15。
- 再次左移，变成30。
- 5乘以0，结果是30，累加器现在是30。
- 左移，变成60。
- 最后，5乘以1，累加到60，结果是65，累加器现在是65。

**除法操作通过减法和移位实现**

**基本原理：**

1. **分解除数**：将除数通过移位操作不断扩展，直到它接近或超过被除数。每次移位相当于乘以 2，类似于快速的二进制倍增。
2. **减法和移位**：通过从被除数中减去逐渐增加的除数的倍数，直到被除数变得小于除数。商的位数通过移位来构建。
3. **重复步骤**：直到被除数变为零或小于除数，最终商是移位和减法的累积结果。

**算法步骤：**

假设我们要计算 **a ÷ b**，其中 a 是被除数，b 是除数。

1. 准备

- 初始化商为 0。
- 初始时，将除数 b 移位，直到它接近被除数 a。

2. 操作

- 将除数 b 左移一位（即乘以 2）直到它大于等于被除数 a。
- 对于每一位，将这个扩展后的除数减去被除数，并将商的相应位设为 1。
- 对被除数进行减法操作，并记录商的当前位。
- 继续左移除数并重复此过程，直到被除数小于除数。

3. 完成

- 最终，商将通过这些步骤得到。

示例：**13 ÷ 5**

我们来详细看一个示例：**13 ÷ 5**。根据上述原理，我们用减法和移位来进行：

1. **初始状态**：
   - 被除数 **a = 13**，除数 **b = 5**，商 **q = 0**。
2. **扩展除数**：
   - 左移除数 b（5），得到 10（5 × 2）。
   - 由于 10 <= 13，继续进行。
3. **开始减法**：
   - 从 13 减去 10，得到 3。
   - 在商中，记录下当前位：商现在是 **1**。
4. **继续扩展**：
   - 再次左移除数 b，得到 20（10 × 2），但 20 > 3。
   - 因此，不进行减法操作。
5. **结束**：
   - 商最终是 2，余数是 3。

所以，**13 ÷ 5 = 2**，余数为 3。

运算器的结构可以根据机器的类型和功能进行灵活设置。

### 8.控制器的基本结构和功能

功能：

控制器的功能是解释指令，从取指到分析，到取操作数，到执行指令，一直到保存结果，这个过程都由控制器来控制完成。

1.解释指令

2.保证指令的按序执行

**完成一条指令的过程**

控制器的基本结构包括PC（程序计数器）和IR（指令寄存器）。执行一条指令的过程分为三个阶段：取指令、分析指令和执行指令。

1.取指令          PC(程序计数器)

2.分析指令      IR(指令寄存器)		 

3.执行指令      CU(控制单元)

PC存放当前欲执行指令的地址具有计数功能：(PC)+1 -> PC

IR存放当前欲执行的指令

取指令需要通过PC来获取指令的地址，然后将指令存入IR。分析指令将操作码部分送给控制单元进行分析。执行指令需要将地址码部分送给存储体，将数据取出并存入ACC寄存器。

**运算器，控制器，存储器构成了什么？**

计算机的硬件结构包括运算器、控制器和存储器，它们构成了计算机的主机。

**主机完成一条指令**

在主机上执行一条指令的过程包括取指令、分析指令和执行指令。

**程序在计算机上怎么运行**

通过输入设备将程序和数据保存到计算机的内存中，然后通过控制器将程序的首地址送入PC，启动机器开始执行程序

1.将程序通过输入设备送至计算机

2.程序首地址 ---> PC

3.启动程序运行

4.取指令 PC ---> MAR ---> M ---> MDR --->IR

5.分析指令 OP(IR) ---> CU

6.执行指令 Ad(IR) ---> MAR ---> M --->MDR --->ACC

7.打印结果

### 9.计算机硬件的主要技术指标

**1.机器子长**

CPU一次能处理数据的位数

与CPU中的寄存器位数有关，通常情况下，机器子长和CPU里面寄存器的位数是相等的

机器子长越长，机器性能越好

**2.运算速度**

1.主频：CPU时钟周期的频率，CPU的指令操作是在时钟信号控制下，每周期逐步完成的，因而主频在一定程度上能够反应CPU的运算速度

2.核数，每个核支持的线程数：CPU中每个核心都是能够独立执行某个程序/线程的处理器，高荷载下每个核心都能尽量保证自己的效率的稳定，但多核的优势也需要系统/程序进行对应的优化才能发挥作用，执行某些复杂的大型程序时，核心之间也需要相互配合才能完成工作，因而并不是多一个核心速度就能快一倍

主频与核心数只能说是硬件为了应对工作而进行的准备，因而并不能很好的反映实际的工作效率

3.吉普森法

吉普森法（Gibson's method）是一种计算机性能评价方法，它通过计算等效指令速度来衡量计算机的性能。等效指令速度是在指令执行速度的基础上，通过考虑每条指令的执行时间以及它们在全部操作中所占的百分比，来计算出一个等效的指令执行速度。这种方法能够更全面地反映计算机在不同程序下的性能表现。

等效指令速度的计算公式为：

$$
T = \sum_{i=0}^{n} (w_i \times t_i)
$$

其中：

其中：
- T 表示等效指令的执行时间，
- w_i 表示第 i 类指令在程序中所占的比例，
- t_i 表示第 i 类指令的执行时间，
- ∑ (sigma) 表示求和，
- i 从 1 到 n 变化，
- n 为指令类型的种类数。

通过计算各类指令的加权平均执行时间，可以得到一个等效的指令执行速度，用于衡量计算机的整体性能。

4.CPI 执行一条指令所需时钟周期数

5.MIPS 每秒执行百万条指令

6.FLOPS 每秒浮点运算次数

**3.存储容量**

存放二进制信息的总位数

主存容量

- 存储单元个数 × 存储字长
  - 例如，MAR（存储器地址寄存器）容量为 10 × 8 位 = 1 K × 8 位
  - MDR（存储器数据寄存器）容量为 16 × 32 位 = 64 K × 32 位
- 字节数
  - 2^13b=1 KB（1K = 2^10）
  - 2^21b=256 KB（1B = 2^3b）

辅存容量

- 字节数 80 GB

这里的“主存”通常指的是RAM（随机存取存储器），而“辅存”则通常指的是硬盘驱动器或其他类型的非易失性存储。存储单元个数指的是存储器中可以存储数据的单元数量，存储字长指的是每个存储单元可以存储的位数。字节数是衡量存储容量的单位，1字节（Byte）等于8位（bit），1千字节（KB）等于210210字节，即1024字节。

## 第二章 计算机的发展与应用

### 1.计算机发展的驱动力

计算机本质就是用于计算的机器，因而其发展的一大驱动力就是人类，从国防到公司团体再到个人，对实现高速运算需求的不断扩展

技术的发展也起到了很大的作用，主要是**硬件(电子技术)**的不断发展，和**计算机体系结构理论**的发展完善

其中硬件(电子技术)的发展对现代计算机的发展起到了决定性的作用，因而计算机的更新换代就是电子技术的更新换代

### 2.微处理器和微型计算机

微处理器是指一片高度集成化的电路，包含控制器，运算器，所构成的处理核心，也就是我们平时所说的CPU

微型计算机是指使用维处理作为处理核心，高度集成化的，面向个人用户，体积小，重量轻，价格低的计算机型，也就是我们平时所说的电脑

### 3.摩尔定律

摩尔定律是Interl公司创始人之一Gordon Moore所提出的，CPU发展过程中，新一代的CPU约每隔18-24个月就会发布，其包含的晶体管数量便会较上一代增加一倍，性能也会提升一倍，从而1美元能够购买到的算力每18-24个月便会增长一倍

然而随着晶体管的不断缩小，集成度不断增大，集成电路芯片已经逐步顶到了电介质传导速度和量子隧穿效应两大天花板，导致如今的发展较摩尔定律预测逐步放缓，逐渐达到集成电路这种构造模式的瓶颈，以至于停滞不前

CPU/微处理器芯片正期待着能有更先进的构造技术，打破集成电路的瓶颈，以迈向新世代

### 4.计算机软件的发展

计算机软件技术的发展主要是编程语言和系统软件的发展过程

早期的编程直接使用机器语言，对应硬件指令集进行编程，后来逐渐发展出汇编语言，相比机器语言更容易记忆，之后出现的面向过程，面向对象的高级语言使程序员不必在意底层的硬件实现，可以直接针对问题进行编码

系统软件是面向硬件编程，管理硬件资源，解决硬件问题，为上层软件提供/维护运行环境的一类软件，操作系统是系统软件的一类，是软件的底层。系统软件的应用使上层软件开发者，计算机的使用者不必在意底层的硬件工作。语言处理程序(汇编，编译，解释程序)，服务性程序（装配，调试，诊断，排错），数据库管理系统，网络软件也属于系统软件

现代软件的特点是，代码量大，制作成本昂贵，软件测试/质量检测流程复杂。软件的开发依赖多人协作编码完成，开发周期长

输入域测试，代码覆盖测试，路径覆盖测试，是软件测试的一些基本策略，但对于现代软件而言这些测试也需要消耗大量的人力物力，并且往往只针对某个单元进行全面覆盖，因而软件出现漏洞，出现bug，造成损失，只能尽量规避，无法完全避免

## 第三章 系统总线

### 1.总线的基本概念

冯·诺依曼结构定义了计算机组成的五大部分，即使我们将控制器和运算器组合为CPU，将I/O设备统一，依然有三大部分，而现代计算机在此基础上还有扩展，例如GPU，外部设备等等

我们需要将各个部件**联接**起来，进行**信息的传输**交互才能发挥各部分的效能，构成计算机这个整体

两两互联是联接的基本方式，但现代计算机的部件数量庞大，印刷电路板空间/制作工艺有限，这种方式也不利于部件的扩展，那么我们不妨将两两互联的线路扭合起来，形成公共的通路，每个部件只需接入公共通路就能和其它所有部件进行通信

**总线**（Bus）是计算机各种功能部件之间传送信息的**公共通信干线**，是各个设备共享的传输介质，其本质是信号的公共传输线

**同一条总线上，同一时间只允许一对设备进行相互通信**

**总线进行数据传输有两种模式，一种是串行传输，另一种是并行传输**

总线中能够传输一位二进制数据的通路称之为一条**信道**

串行传输只**使用一条信道**，逐位发送一串二进制数来传递数据

并行传输则根据数据/变量的二进制组成，**使用多条信道**同时发送多位二进制数据

并行适用于短距离传输，串行适用于长距离传输。

信号的传输需要遵循一定的**频率**（把电流变化曲线按频率切割根据高低判断0/1），在频率相等的情况下并行传输的速度要快于串行传输

但并行传输存在信号的干扰（电磁学），尤其是在**高频率/长距离**下，过强的信号干扰会导致无法正确的传输0/1数据

并行传输在短距下具有速度优势，串行传输在中长距下具有速度优势

高速数据传输技术依托于传输频率上限不断提高，不受传输频率上限影响的串行传输成为高速数据传输的主流

而当下计算机中数据传输，短距（板内，板间）以并行传输为主，长距（外设，计算机之间）以串行传输为主

单总线结构存在瓶颈问题，因此引入多条总线可以提高数据传输效率。双总线结构可以解决CPU和主存之间的繁忙问题，但仍需要CPU作为媒介进行外部设备和主存之间的信息传输。以存储器为中心的双总线结构进一步改进了系统效率，但目前仍需分时进行数据传输。

### 2.总线的分类

首先按照总线的位置可分为**片内总线**和**系统总线**

片内总线实现的是**单块芯片内部**各部件之间的传输通信

而系统总线则是实现**芯片与芯片之间**，之前提到的计算机**各个组成部件之间**的信息传输

系统总线根据传输信息/信号类型的不同，又可分为**数据总线**，**地址总线**，**控制总线**

数据总线通常是双向的，其信道宽度与机器字长，存储字长有关（通常小于）

地址总线通常是单向的，其信道宽度与存储地址长度，I/O地址长度有关（通常相等）

控制总线通常是双向的，需要传输来自CPU的控制信号，来自设备的状态反馈，总线的使用许可，中断请求等等信息

片内总线和系统总线都是用于单一计算机/设备内部各部件之间的数据传输，而计算机与计算机之间，计算机与其它设备进行**跨设备信息传输交换**的总线，我们称之为**通信总线**

### 3.总线特性及性能指标

主板就是计算机中最大的总线，它提供了各个接口，让不同的部件能够连接在一起，从而构成整个计算机

为了实现设备通过接口与总线的有效连接，总线就需要拥有一定的机械特性，电气特性，功能特性，时间特性

机械特性是总线与相应接口在制作时的尺寸构造，针脚排列规范，电气特性包括信号的传输方向，电平的高低范围，功能特性是总线在传输信息/信号类型上的针对性分类，可以分为：数据，控制，地址。时间特性是总线信号间的时序关系

总线的性能通过以下指标进行描述：

1.**总线宽度**（传输带宽），等同于总线中数据线/信道的数量，决定了总线能够同时传输的数据位数

2.**标准传输率**，以每秒传输的最大字节数（MBps）来衡量

3.**时钟特性**，数据传输的收发是进行同步进行，还是非同步进行（异步为非同步的一种），以及使用怎样的时钟频率进行数据的收发

4.**复用性**，只能单一传输一种类型的数据（数据，地址）还是能够传输多种类型的数据，例如inter 8086CPU16条地址总线同时复用为数据总线，复用性可以减少芯片的管脚数量，从而有利于芯片的封装

5.**信号线数**，各功能类型总线的总和

6.**控制方式**，（突发，自动，逻辑，仲裁，计数）

7.**其它指标**，如负载能力等等

### 4.总线标准

总线标准是各类主板制造商和各类部件/设备制造商之间的协议，保证了由不同生产商制作的主板和各个部件能够被集成在一起工作

总线的标准随着计算机硬件技术的不断发展，向着高速度，高扩展的方向不断更新和完善

| 总线标准      | 数据线           | 总线时钟                                                     | 带宽                                                         |
| :------------ | :--------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| ISA           | 16               | 8 MHz (独立)                                                 | 16 MBps                                                      |
| EISA          | 32               | 8 MHz (独立)                                                 | 33 MBps                                                      |
| VESA (VL-BUS) | 32               | 32 MHz (CPU)                                                 | 132 MBps                                                     |
| PCI           | 32 64            | 33 MHz (独立) 66 MHz (独立)                                  | 132 MBps 528 MBps                                            |
| AGP           | 32               | 66.7 MHz (独立) 133 MHz (独立)                               | 266 MBps 533 MBps                                            |
| RS-232        | 串行通信总线标准 | 数据终端设备(计算机)和数据通信设备(调制解调器)之间的标准接口 | 数据终端设备(计算机)和数据通信设备(调制解调器)之间的标准接口 |
| USB           | 串行接口总线标准 | 普通无屏蔽双绞线 带屏蔽双绞线                                | 1.5 Mbps (USB1.0) 12 Mbps (USB1.0) 480 Mbps (USB2.0)         |

ISA是工业标准数据总线，VESA是通用图像/视频传输总线

PCI是外设标准总线，它与外部设备构成了一种中介缓冲器模式，用于对内外时钟频率差异的进行适配，从而外部可以对设备进行任意的添加而不影响CPU的工作，导致计算机性能降低

AGP是interl推出的点对点局部传输总线，主要用于连接CPU（控制芯片）和GPU（显卡）

RS-232和USB是常见的串行接口总线标准

### 5.总线结构

#### 1.单总线结构

最简单的总线结构就是**将所有设备都联接到一条总线上**，这种结构实现简单，扩展性强，但由于单总线**同一时间，只允许一对设备进行传输交互**，其它设备需要传输时就需要等待正在使用总线的设备释放总线，这种设计会导致系统中存在总线资源的抢占问题，容易成为**系统的瓶颈**

例如当I/O设备与主存进行数据交换时，CPU就无法从主存中获取指令和数据，导致CPU停止运行大大影响效率

#### 2.以CPU为核心的双总线结构

以CPU为核心的系统结构中，以CPU中心发出两条总线，一条专用于与I/O设备传输数据，一条专用于与主存传输数据

通过M总线这条专用总线，解决CPU与主存之间存在繁忙的数据交换，一定程度上提升了CPU的运行效率

但这样的结构依然存在问题，当主存与I/O设备之间需要传输数据时，就需要CPU作为中介才能完成数据传输，依然会打断CPU的运行

#### 3.以存储器为核心的双总线结构

**现代计算机总线结构的基础**

从主存发出两条总线，系统总线用于连接主存和其它部件（也包括CPU），存储总线专用于连接CPU

从而CPU能够与主存之间通过存储总线进行高速的信息交换，并通过系统总线完成其它部件之间的信息传输

不过这种结构下，主存依然无法同时使用两条总线进行数据交换，现代的双口存储器依然需要使用**分时机制**来完成分别完成两条总线上的数据交换

但随着计算机技术的不断发展相信有一天，能够实现主存数据对系统总线和存储总线的同时传输交换

#### 4.通道连接的主存总线与I/O总线结构

通过通道连接I/O总线，实现I/O设备与CPU和主存之间的通信

通道是一种特殊的，结构简单的处理器，其程序**由操作系统进行编写**，并可独立运行

有关这种结构，以及通道的详细知识会在计算机体系结构中讨论

#### 5.三总线结构

##### 1.CPU为核心扩展DMA总线

在以CPU为核心双总线结构的基础上

扩展出一条DMA（直接存储器访问）总线，用于高速I/O设备与主存之间的高速数据交换

##### 2.Cashe三总线结构

主存的信息交换速度大约每10年才能增加一倍，相比CPU的更新速度，主存速度就成为了瓶颈

为此现代计算机体系结构中引入了Cashe（高速缓存），作为CPU与主存之间的中介

在CPU运行时，Cashe会预先加载之后可能需要的数据，并与CPU实现高速的数据交换，从而避免主存的速度瓶颈

局部的高速I/O控制设备可以接入到CPU与Cashe之间的局部总线上

系统总线扩展出扩展总线接口和扩展总线，其它设备可连接至扩展总线上，并通过接口与系统总线连接，从而实现外设和内部主存之间的数据交换

但由于其它设备均连接到扩展总线上，外部设备的工做效能可能受到影响

#### 6.四总线结构

四总线结构解决了Cashe三总线结构中，外部设备均接入扩展总线，运行效率受到影响的问题

由Cashe桥扩展出高速总线，实现高速外设与CPU的数据交换

再由高速总线，引出扩展总线接口和扩展总线，连接其它低速设备

通过分别组织高速和低速设备总线，提示数据传输效率

#### 7.传统微型计算机总线结构

当下个人计算机使用的基本总线结构，系统总线连接CPU和主存，扩展出标准总线控制器，I/O总线，连接其它设备

#### 8.VL-BUS总线结构

系统总线扩展出VL-BUS高速总线，连接高速设备（例如图形设备）

VL-BUL总线再扩展出总线控制器，ISA/EISA总线连接低速设备

#### 9.PCI总线结构

与VL-BUS总线结构类似

系统总线扩展出PCI桥和PCI总线连接高速设备，再由PCI总线扩展出标准总线控制器和ISA/EISA总线连接低速设备

PCI总线结构的缺点是当PCI总线上连接设备过多时，总线带宽不够，导致总体性能下降

为此引入了多层PCI结构，通过桥电路扩展出多级总线

### 6.总线控制

当总线连接了多个设备时，由于**同一时间只允许一对设备使用总线进行相互通信**，因而设备在需要通信时会向总线发出**占用申请**，在得到占用许可后通过总线完成数据交换

因而总线控制需要解决**判优控制**和**通信控制**问题

判优控制是当多个设备发送占用申请时，如何合理的分配总线资源

通信控制是使用总线完成通信时，如何保证数据传输的速度和准确性

总线传输周期分为四个阶段

1. **申请分配阶段**：主模块向系统提出申请，总线仲裁器决定哪个模块可以使用总线。
2. **寻址阶段**：主模块向从模块发送地址和命令，指示从模块准备数据传输。
3. **传数阶段**：主模块和从模块之间进行数据交换。
4. **结束阶段**：主模块完成数据传输后，撤销有关信息，释放总线资源

申请分配阶段需要通过**判优控制**来决定设备是否能占用总线进行通信

寻址阶段和传输阶段共同构成通信阶段，需要**通信控制**来保证数据收发，命令发送响应的有序和准确

#### 1.总线判优控制

根据能否发出总线占用申请，我们将总线上的设备分为两类

**主设备**(模块)是通信的**主导方**，能发送总线占用申请，在占用总线后对总线，及从设备的通信具有控制权

**从设备**(模块)是通信的**被动方**，只能相应主设备的通信请求，完成通信一些设备既可以作为主设备也可以作为从设备

有的总线只允许有一个主设备，有的总线允许有多个主设备

**总线判优控制分为：集中式和分布式**

集中式中判优逻辑由一个部件（CPU）完成，分布式中判优逻辑有多个部件协调处理

集中式又可分为链式查询，计数器定时查询，独立请求 三种

#### 2.链式查询方式

链式查询模式是结构最简单的一种控制模式，多用于微型计算机，嵌入式设备中

数据线和地址线完成总线的数据传输功能，此外还有3条控制线传递控制信息

BR(bus request)总线请求信号线，所有设备都使用这条线路来发出总线占用请求

BS(bus busy)总线忙信号线，用于获得占用许可的设备向控制部件反馈/设置通信控制信息

BG(bus grant)总线占用许可信号线，用于链式查询发出总线占用信息的设备

首先I/O设备从BR线向控制部件发送占用申请，之后控制部件通过BG线传输授权许可，**许可信号会链式寻访每个I/O设备**，轮询是否需要占用总线，当遇到需要占用总线的设备时，该设备**截取**控制权，BG线信息不再向后传输，获得控制权的设备通过BS线反馈通信信息，展开通信

之所以需要链式寻访，是由于控制信号统一由BR线送达控制部件，因而**不经过轮询，控制部件并不知道究竟是那一个I/O设备发出了占用申请**

链式寻访模式的一大优点是，我们会**按照优先级来布置BG线的寻访顺序**，优先级高的I/O设备可以接入靠前的接口，从而在同时发送占用申请时，能够被先轮询到，优先截取占用权

此外链式寻访还具有**结构简单**，**设备易扩展**等优点

链式寻访的缺点是，**对电路故障敏感**，尤其是BG线，一旦线路或是某个接口出现故障，导致信号传输中断，之后的I/O设备占用申请将永无应答

但我们可以通过增加BG/BS信号线条数，来**快速实现可靠性的增强**

另一大缺点是授权信号链式寻访，当连接设备过多时BG线容易成为瓶颈，降低整体运行效能

#### 3.计数器定时查询方式

数据线和地址线完成总线的数据传输功能

控制线为**BS(总线忙)，BR(总线占用请求)，设备地址信号线**

总线控制部件内部有一个**计数器**，当设备通过BR线向总线控制部件提出占用请求后，计数器下标会进行初始化，随后按一定方式进行递推，总线控制部件将根据计数器下标寻访对应的I/O设备

与链式查询不同，计数器定时查询模式中**寻访逻辑可编程**，我们可以灵活设定计数器的初始值以及递推方式，例如固定初始化为K来提升K位置及之后的I/O设备优先级，使用上一次相应的值从而循环优先级，或使用一个数组来安排优先级顺序

设备地址信号线的宽度要与I/O接口的总数对应，能够将所有I/O接口用二进制状态编码表示

#### 4.独立请求方式

相比前两种模式需要按一定顺序查找提出占用请求的设备，独立请求模式为每个I/O接口链接了专属的BR和BG线，从而可以进行独立的占用请求发送和应答

总线控制部件根据BR线的来源就能获知发送占用请求的设备，优先级的排序通过总线控制部件内部**排队器**这一特殊的集中电路完成，其逻辑也可以进行编程控制

#### 5.总线通信控制

获得占用总线许可后，主从设备将展开通信，在此过程中需要总线通信控制来协调双方的数据交换过程，保证收发数据的有序准确

**同步通信**按照CPU时钟的高低电频形成的**时钟频率**，作为统一时标，主从设备会根据时钟频率来同步每个时段内需要完成的工作

**异步通信**是采用应答模式，主设备发送请求，从设备发送应答信号，之后进行相应的命令执行和数据传输

**半同步通信**，通过结合同步和异步，解决不同运行速度的设备之间的通信

**分离式通信**，是最为高效且复杂的模式，能够充分挖掘系统总线每一瞬间的潜力

##### 1.同步式数据输入

同步通信的特点是一定要有定宽，定距的周期来控制通信过程，主从设备各种操作的执行

CPU的高低脉冲信号会形成**时钟频率**，主从设备需要按照时钟频率，在**相应的周期内，相应的时间点之前，完成相应的工作**

每个周期始于上一周期末尾的低电平变为高电平时的**上升沿**，保持一定时间的高电平后，变为低电平（包含一个**下降沿**）并结束于下一周期开始前的上升沿

同步方式要求主从设备强制按照时标进行操作/运行同步，因而会受到短板效应的影响，在高速设备和低速设备之间的通信中，必须按低速设备的频率来设计通信流程，高速设备的效能会有所降低

多用于设备之间存取速度相近时的通信控制

![img](https://pic4.zhimg.com/v2-9ce810862ecbbb424c0d0255d351c935_b.jpg)

以数据输入(读命令)的执行为例

首先在T1周期上升沿之前，主设备要通过地址线给出需要读取数据的地址

在T1周期内，T2周期上升沿之前，主设备需要给出读命令信号

T2周期，T3周期上升沿之前，从设备需要将要读取的数据拷贝至接口寄存器并给出数据信号

T3周期，T4周期上升沿之前，主从设备完成数据的发送和接受，同时读命令信号撤销

T4周期，T5周期上升沿之前，地址信号被撤销

##### 2.同步式数据输出

![img](https://pic4.zhimg.com/v2-6501cfa0bc37db64d67debc10a7ea1e9_b.jpg)

写入操作执行为例

首先在T1周期上升沿之前，主设备要通过地址线给出需要写入数据的地址

T1周期高电平阶段，下降沿之前，从设备准备好写入，并发送数据信号

T1周期低电平阶段，T2周期上升沿之前，主设备接受数据信号给出写入命令

T2周期与T3周期，需要完成数据向接口寄存器的写入，以及接口寄存器向写入地址位置存储体的数据写入

T4周期上升沿之前，从设备需要确认写入完成，主设备撤销写入命令信号

T4周期内，T5周期上升沿之前，地址信号撤销

##### 3.异步通信

异步通信采用**请求&应答模式**，不设置统一的时标来同步进程，设备之间独立进行运作，何时接受到命令/数据，何时执行相应的操作

异步通信需要增设请求线路和应答线路

![img](https://pica.zhimg.com/v2-7359421874a1498f576c273d62077830_b.jpg)

异步通信可分为**不互锁(左)**，**半互锁(中)**，**全互锁(右)**三种模式

不互锁模式是最为简单的，由主设备发送请求信号，从设备接受到请求信号后进行应答，一段时间后主设备和从设备的请求/应答信号自动撤销（不管对方是否有接收），不互锁模式可靠性较低

半互锁模式在不互锁的基础上，要求主设备必须得到应答才撤销请求信号，但从设备应答信号依然经过一段时间就自行撤销，半互锁较为可靠，但**由于从设备不检测主设备是否成功接收应答，可能导致长时间的请求**

全互锁在半互锁模式基础上，要求从设备必须确认主设备撤销请求（主设备收到了应答信息），才会撤销应答信号，全互锁能够完成最可靠的异步通信

如果主设备接收数据发现有误，半互锁和全互锁下，主设备可以要求从设备再次发送数据

##### 4.半同步通信(同步，异步结合)

半同步通信是同步通信和异步通信的结合，因而具有两者一定程度上的特征

半同步通信中也会使用一定的时钟频率来规范信号的收发，**主设备使用时钟前沿发送信号，从设备使用时钟后沿判断识别信号，反馈响应**

但与同步通信不同的是，半同步通信不要求主从设备必须在某个时钟周期中共同完成固定的工作，而是按照自己的运行速度，独立运行

![img](https://pic4.zhimg.com/v2-8ba40ae07095c7c0a15c34c66736bd15_b.jpg)



当主设备于T1周期发送完指令后，在T2周期结束前，若从设备无法完成相应的指令，发送反馈信号/提供数据，从设备会在T2周期内发送**WAIT信号**（以WAIT信号线低电平表示），主设备会在T3周期到来前一刻，检测WAIT信号，若为低电平则主设备于T3周期等待从设备完成工作

从设备如果未在n个周期内完成工作将一直发送WAIT信号，主设备在此期间可以执行其它任务，直到从设备在n+1个周期结束前完成准备工作取消WATI信号并发送反馈，主设备会在n+2个周期与从设备进行数据的收发，同时撤销命令信号，n+3个周期主设备撤销地址信号

##### 5.分离式通信

主从设备收发数据大致可划分为三个过程：

1.主设备发送地址和指令信号（使用总线）

2.从设备准备数据（不使用总线）

3.主从设备完成数据收发（使用总线）

过程2，实际主从设备并未使用总线进行数据交换，但在之前的三种通信模式中会保持占用

而分离式通信正是在过程2时，让主从设备放弃总线占用，让其它真正需要使用总线收发数据的设备来占用总线，**避免占而不用的情况**，从而挖掘总线每一瞬间的潜能

当从设备准备好数据来到过程3时，将**由从设备发出占用总线请求**（变为主设备），占用总线后将数据发送给主设备（变为从设备）

分离式通信的特点是要求所有设备都有权申请总线占用（都能作为主设备），收发数据采用同步模式进行，各个设备准备数据时不占用总线，总线被占用是一定进行数据交换（没有占而不用的情况）

## 第四章 存储器(上)

存储器是现代储存程序计算机中重要的组成部件之一，计算机运行时的程序指令，数据都保存在存储器中，改进型的冯·诺伊曼结构也是以存储器为核心

### 1.存储器的分类

**1.按存储介质分类**

可分为**半导体存储器，磁介质存储器，磁芯存储器，光盘存储器**

我们使用的内存条，U盘都属于半导体存储器，半导体存储器又可分为TTL(Transistor-Transistor-Logic)晶体管-晶体管逻辑型存储器和MOS(Metal-Oxide-Semiconductor Field-Effect Transistor, MOSFET)金属氧化物半导体效应场管型存储器

TTL型存储器集成度低功耗高但速度快，MOS型存储器集成度高功耗低，现代计算机存储器主要是MOS型

磁盘，磁带都属于磁介质存储器，在金属表面涂抹磁层，作为**磁载体**，利用磁化方向的不同来表示0和1，磁盘表面每一圈可保存0/1的同心圆称之为**磁道**，由小到大磁道弧排列形成**扇区**，以扇区为单位进行数据的存储

磁介质存储器在读取数据时需要通过**磁头**移动寻找扇区，并判别磁道不同位置的磁化方向/或施加相应的磁化从而完成数据的读写

磁芯存储器(Core Memory)，通过横纵导线磁环构成，是计算机芯片内部的存储器，曾为计算机发展做出一定的贡献

光盘存储器采用激光和磁光材料，进行数据的存储和读写

半导体存储器是**易失型**存储器(RAM)，需要持续供电来维持数据保存，断电后数据丢失，另外三种存储器都是**非易失型**(ROM)，能够在断电后保存数据

**按存取方式分类**

可分为**随机访问**存储器和**串行访问**存储器

随机访问存储器存取时间与物理地址无关，只要给出地址就能进行寻址访问，例如内存

随机访问存储器又可分为随机存储器(程序执行中可读可写)，和只读存储器(用于存放系统参数等只读常量)

而串行范围存储器，存取时间与物理地址有关，根据地址的不同存取时间会有所差异，需要针对物理地址位置进行一定的调整才能完成数据的读写，例如磁盘，磁带

串行存储器又可分为顺序存取存储器，例如磁带，只能按物理地址顺序读写，和直接存取存储器，例如磁盘，可以在任意指定位置读写数据，但磁头需要根据物理位置进行一定的调整

**按作用分类**

![img](https://picx.zhimg.com/v2-5468cc51d6c01e82c273a86080296e2d_1440w.jpg)

主存储器可分为RAM和ROM，易失性和非易失性，RAM容量小高速但断电后数据会丢失（内存），ROM容量大低速能在断电后保存数据（硬盘）

闪存(Flash Memory)其实属于EEPROM(电擦除可编程只读存储器)，它的读取速度较ROM更快，可以进行反复擦写，并且能在断电后保存数据

我们使用的**U盘**就属于闪存，一些高性能的微型计算机可能直接将闪存作为硬盘使用，就是所谓的**固态硬盘（SSD）**

闪存不能像RAM那样以字节为单位改写数据，因而不能取代RAM

闪存也可以用做主辅存储器之间/寄存器主存之间的速度调剂，即**缓存**，我们可以在读取数据后提前预取附近位置的数据到缓存中，如果之后需要读取的数据恰好已经被保存到了缓存中，就可以直接读取缓存，称之为“**缓存命中**”

**CPU寄存器和内存之间就会使用Cache高速缓存**，一些磁盘也会使用SSD阵列作为缓存提高读取速度

辅助存储器是指光盘，磁盘，磁带一类外部低速存储器

与辅存相比，主存的特点是容量小，速度快，成本高。

### 2.存储器的层次结构

![img](https://pic2.zhimg.com/v2-8b795bb5a23a3b4ad32feff1636984df_1440w.jpg)

用户的需求通常希望存储器能够有更低的价格，更大的容量，更快的速度

但实际并**没有任何一种单一的存储器能够兼顾这三方面的优势**，因而存储器形成了如上图所示的**层次结构**，在不同层次，不同的存储器之间通过**硬件接口，软件适配，或是软硬件结合**的方式进行**连接**，从而构成一整套计算机**存储体系**，从而**整个存储体系能够做到三方兼顾**

寄存器是直接部署在某一硬件部件内部的容量低，但速度极快的存储器，是硬件运行时能直接访问到的，直接进行处理的数据，除了CPU，I/O设备中也会布置寄存器

其中部分寄存器是提供给机器语言程序员进行编码读写控制的，也有部分寄存器运行固定的预制硬件逻辑，对机器语言程序员透明

对于上层的程序员来说，我们不需要考虑存储体系的层次结构，只需要将其看作一个整体进行数据的读写即可，信息在不同层次间的传递，会通过相应的**连接方式**(软件，硬件，软硬结合)自动完成

**缓存---主存---辅存**

![img](https://pic1.zhimg.com/v2-0a608a77240d102a0d013c311b9e1252_1440w.jpg)

程序运行时，CPU需要将主存中保存的指令，数据读如到寄存器中执行

而对于某些大型程序，或是部分大容量的数据，资料，由于主存容量有限，可能还需要主机外部可扩展的辅存来存储，因而主存---辅存之间会通过硬件接口和软件适配结合的方式，完成数据的传递交换，构成一个存储整体，称之为**虚拟存储器**

我们在进行程序编写时，看到的地址是对应虚拟存储器的**虚地址/逻辑地址**，在程序实际运行时，会通过一定的机制将虚地址转为真实的物理地址

对于上层软件的开发者来说，不需要考虑这个存储整体的数据传输，通常只需要将它们看作一个整体进行调用即可，一些情况下可以通过编码控制数据/资源，从辅存到主存，或是在主存内部(RAM ROM之间)的加载和卸载

此外，由于CPU的运行速度提升（摩尔定律）较主存速度快，因而我们会在主存和CPU寄存器之间架设缓存(Cache)，来适配两者的速度差异

缓存通过每次CPU访问主存后，对访问附近位置的数据进行预取加载，利用程序的**时间局部性**和**空间局部性**，从而在之后CPU需要访问主存时就可能出现“缓存命中”，从而直接获取预加载好的缓存数据

缓存---主存，直接使用主存地址，或者说**对数据只记录主存地址**，即便数据被预加载到缓存中，其地址仍表示为主存地址，从而CPU在访问时按主存地址寻访即可，若**相应主存地址处的数据已经预加载到了缓存中**，则优先获取缓存中预加载的数据到CPU寄存器中

但缓存本身并不是没有地址，在完成缓存--->CPU寄存器的数据读取过程中，CPU提供的主存地址会转换为对应的缓存地址，从而读取缓存中对应的数据

主存储器地址又称之为**物理地址/实地址**

缓存和主存之间通过预制硬件逻辑进行连接，对程序员是完全透明的

### 3.主存储器

**主存储器的组成结构**

![img](https://pica.zhimg.com/v2-cec72635ac14e491e1f143a256865e8a_1440w.jpg)

如上图，我们细化了之前给出的主存储器组成

地址总线连接在MAR上，向MAR单向传递地址，地址数据经译码器，驱动器转换，从而在存储体中选定对应的存储单元

数据总线连接在MDR上，可进行双向数据传到，通过控制电路发送读/写信号决定是将MDR中的数据写入存储体，还是将存储体的数据读出MDR再传递到数据总线上

**主存与CPU之间的联系**

![img](https://picx.zhimg.com/80/v2-1791fbcb04972d2bbfb4716d7d5b0c2d_1440w.webp?source=d16d100b)

**主存中的地址分配**

1比特(bit)存储一个基本的二进制位 0或1

8比特组成1字节(byte)，主存中的地址按字节由高到低进行分配

而最小的寻址单元则是1字(word)，根据环境的不同，1字长可能是4字节，也可能是8字节



以一个 int32 为例，它需要32位 4字节的空间进行存储，我们会将其保存在连续的4字节中

但有两种不同的存储方式

![img](https://picx.zhimg.com/80/v2-b6171c1db7b7c2072dbf4fbcc4f2c4e0_1440w.webp?source=d16d100b)

**大端模式**中，我们会按从高到低的顺序，存储int32的数据，并且此时以高位字节的地址，作为字地址

**小段模式**中，则按从低到高的顺序进行数据存储，并以低位字节地址作字地址

两种方式本质上并没有太大区别，但分别使用两种存储方式的设备在进行相互通信时，**接收方就需要对接收数据的字节顺序进行调整**



![img](https://pic1.zhimg.com/80/v2-af878506291a2a4348802896e0be15ab_1440w.webp?source=d16d100b)

若地址线为24根线，那么其所能表示的不同字节的地址，就可映射为24位二进制的所有状态

如果进行按字节寻址，能访问到的数据范围就是 2^16 byte = 16MB

若此时1字长为16位 2字节，进行按字寻址时，就需要有1位二进制来表示字内的字节序，另外23位来表示字地址，从而访问到的数据范围是 2^23 word = 8MW = 8*2MB = 16 MB

同样如果1字长为32位 4字节，需要两位二进制表示字节序，另外22位表示字地址，数据范围是2^22 word = 4MW = 4*4MB = 16MB

**存储器的技术指标**

**存储容量**：能够保存的二进制(bit)/字节(byte)量

存储速度：分为存取时间和存取周期，

**存取时间**是指从CPU给出地址信号，到获得稳定的数据输出（**读出时间**），或CPU给出地址信号，到存储器反馈写入完成（**写入时间**）

**存取周期**是两次独立的读/写操作，从第一次开始到第二次开始，之间的最小时间间隔，也分为读周期/写周期

**带宽**：单位时间内能够读/写的数据量,bit/s,byte/s

### 4.半导体芯片

**半导体存储芯片的基本结构**

主存储体由多个存储芯片构成，每个存储芯片在设计上能够独立完成数据的保存和输出，并通过逻辑电路链接，构成整个存储体的存储空间

![img](https://picx.zhimg.com/80/v2-68cff3c13e5de1cf70cf13c47d0738fb_1440w.webp?source=d16d100b)

存储芯片内部组成如图

内存条上这些黑色的方块就是存储芯片

存储矩阵完成数据的保存，

读写电路连接数据线和读写控制线可将数据线上的数据写入到存储矩阵的指定位置，或从指定位置读出数据输出到数据线

译码驱动电路连接地址线，负责解译地址信号，定位存储矩阵的对应位置，译码主要有线选法和重合法两种方式

片选线信号负则定位需要工作的存储芯片，可以让多个芯片同时工作

![img](https://pic1.zhimg.com/80/v2-c1fc59490e756c86a5d05e0418e0f8b2_1440w.webp?source=d16d100b)



地址线宽，数据线宽，和芯片容量关系如下

![img](https://pic1.zhimg.com/80/v2-5137039a95a57dcc5678eb8c1a931a27_1440w.webp?source=d16d100b)

例如第一行：地址线是10代表2的10次方个存储单元，4表示每个存储单元存放4位数据。容量就为2的10次方乘以4.

读写控制线可以由一线 WE 控制，低电平写入，高电平读出；也可以由 OE和WE 两线控制，OE低电平读出，WE低电平写入

片选线信号有 芯片选择 CS(chip select)和 芯片启动/芯片使能 CE(chip enable)两种

片选线会根据存储芯片构成存储体的分组结构进行布置

以用`16K*1位`存储芯片，构成`64K*8位`存储体为例，布置方式如下图

![img](https://picx.zhimg.com/80/v2-65968e4b34314564b843106e672a22c2_1440w.webp?source=d16d100b)

首先为了满足8位的字节长度我们需要将8个存储芯片划分位一组，1byte(8bit)的数据中的每1bit会分别保存在8个存储芯片相同地址处

每1组存储芯片保存16K*8位容量的数据，那么我们就需要4组芯片

相应的64K个地址就会被划分到这4组芯片中，0到16K-1在第一组，16K到32K-1在第二组依次类推

以读取1byte数据为例，当CPU传入64K范围内的地址值给存储器时，经过译码，**对应芯片组上的片选信号会统一置为低电平，从而让这一组存储芯片同时开始读出工作**，从地址总线上获取地址信号，再经过芯片内部译码器进行译码，从而找到CPU地址对应存储矩阵的地址，进而得到对应的1bit数据，最后8个芯片会将每bit数据依次输出到数据总线对应的线路上，从而读出1byte数据

**半导体存储芯片的译码驱动方式**

译码驱动方式为解决在CPU给出地址信号时，存储体如何找到对应的一组存储芯片的问题

译码驱动方式主要有**线选法**和**重合法**

线选法是一种简单的逻辑，地址译码器连接地址总线，同时对连接n组存储芯片对应的n条片选总线

其逻辑就是一个对地址值范围按芯片组容量范围取模的操作，从而将n条片选线中对应的一条置于低电平

![img](https://pic1.zhimg.com/80/v2-1c23dd3a4cdb616764b9d5acda6e6d87_1440w.webp?source=d16d100b)



线选法实现简单，但对于某些大容量存储芯片来说，地址译码器连接的片选线可能过多，例如有1M组芯片时，就需要连出1M条片选线，导致芯片集成度无法做高

为此可以采用重合法，重合法会将芯片组构建一个二维矩阵，对地址信号分别译码出行列地址，并将对应行和对应列上的片选总线置为低电平（类似磁芯存储器）

其交叉位置就是被选中的芯片组，**同时获得行列片选低电平，其输出数据能够进入数据总线中**

**但其它行/列上的芯片也会进行数据的读出，但数据不会传入数据总线**

![img](https://pica.zhimg.com/80/v2-0d6a070b46be152d51198a17600ffb39_1440w.webp?source=d16d100b)

相比线选法，重合法采用二维行列地址的方式进行译码定位，在大容量时线路较线选法明显减少，1M芯片组时，重合法译码器只需延伸行1K，列1K总共2K线

**静态RAM（SRAM）**

如图电路，由T1-T4**双稳态触发器**完成0/1的存储

T5-T6行开关选定需要工作的触发器

T7-T8列开关决定选定行上那个触发器的数据能够被读出，或是需要被写入数据

由于存储元件时双稳态触发器，因而写入时需要在原/非两端同时进行

![img](https://pic1.zhimg.com/80/v2-9c2c63df967c13580681f74f7afdd893_1440w.webp?source=d16d100b)



![img](https://picx.zhimg.com/80/v2-a58c6dc87e7048293e90ef7f2e766640_1440w.webp?source=d16d100b)

读操作

![img](https://picx.zhimg.com/80/v2-7564da849f5a0f2c461e8d865dba3bd9_1440w.webp?source=d16d100b)

写操作，左侧对信号取反输出，原端非端同时传入信号完成写入

**Inter2114芯片**

Inter2114芯片是一个静态RAM芯片其外特性如图

![img](https://pic1.zhimg.com/80/v2-9779671c71ca58675ebd0b881bb7f237_1440w.webp?source=d16d100b)

A0-A9 10路地址线，说明其地址范围为1K

I/O 线4路，说明每地址处数据为4位

因而该芯片容量为 1K*4bit=4096bit

其芯片内部的单个存储元件能够保存1bit(0/1)的数据，构成一个64bit*64bit=4096 容量的存储矩阵

为了实现1K*4bit 地址*输出位的效果，芯片内部的地址译码也采用了和存储器重合法相同的行列布置思路

读操作为例，电路如下图

![img](https://pic1.zhimg.com/80/v2-46aa94b0070fd694da174952aa8a3b7c_1440w.webp?source=d16d100b)



行方向上分配 0-63 共64个行地址码，对应存储矩阵的64行（于重合法相同）

但在列方向上分配0-15 共16个列地址码，**每16个单列为一组，将列方向64单列分为4组**，列地址码对应4组中相应的0-15列

从而行列方向地址码范围 64*16 = 1K ，行码选中1单行存储元件，而列码选中4组中的4列存储元件，从而最终输出1*4=4bit信息

以0000地址信号为例，行译码结果为0，第0行被选中，列译码结果为0，从而4组中对应的0列：0/16/32/48 4列被同时选中，则行列同时被选中的存储元件就是4个，输出4bit信息

写入操作类似，通过行列选择，I/O输入数据并同时写入到A端A'端

**动态RAM（DRAM）**

动态RAM使用电容的充放来保存1和0

如图三管动态RAM电路图

![img](https://pica.zhimg.com/v2-b7eb714aeccc5209523ee9da25139562_1440w.jpg)

单管动态RAM电路图

![img](https://pic4.zhimg.com/v2-44b53d8e74594db78b1a1f2453bfc495_1440w.jpg)



读取时预充信号令T4导通，VDD电压为读数据线充电，读选择信号令T2导通，此时若电容已充电（保存数据1），T1不导通，则读数据线保持高电平（读到数据0），若为充电，T1导通，读数据线放电转为低电平（读到数据0），我们还需取反才能读到正确信息，**读出信息与原存信息相反**

而写入时，写入数据线高电平，T3导通，电容充电（写入1），写入数据线低电平，T3不导通，电容放电（写入0），**写入信息与输入相同**

**Inter 1103芯片**

Inter1103 是使用三管控制电容的动态RAM芯片

译码驱动采用简单的重合法，`32*32`简单二维存储矩阵，规格`1K*1bit`

但特别的是**行地址译码时还需要读写控制信号参与**，行地址译码器对每行片选线分别布置了读/写两条线路（选行同时确定读写操作）

读操作如图

![img](https://pic2.zhimg.com/v2-5dfb694ddbc4441e686814b9b29face7_1440w.jpg)



此外由于电路中电容会漏电，导致数据丢失，因而每隔一段时间，都需要使用刷新放大器对电容中的信息进行刷新重现

**Inter 4116芯片**

Inter4116 是使用单管控制电容的动态RAM芯片

译码驱动采用重合法，简单`128*128`二维存储矩阵，规格`16K*1bit`

外特性如图

![img](https://pic4.zhimg.com/v2-4473afb83ca2ac3486a414155bf93915_1440w.jpg)

内部存储阵列控制如图

![img](https://pic3.zhimg.com/v2-88363ade6793051c51b6c2316ce7544c_1440w.jpg)



Inter4116 16K地址规格需要使用14位地址信号，但其地址信号线只有7条，需要**分两次分别传输行/列地址（7位）**

此外芯片还有一个时序控制器用于产生时钟信号控制内部读写操作

每列上在63和64列之间都有一个读放大器跷板电路，信号输出同非门，但能够对电路信号进行强化，避免因传输过远导致衰弱

**写入时0到63列写入信息与写入数据相反，读出时再次反转为正确**

**动态RAM刷新**

受电容漏电影响，每个一段时间我们需要对电容中的信息进行刷新再生

存储矩阵中每列都有一个刷新放大器，**刷新操作通过行选读出时启用刷新放大器来完成**，每次刷新一单行的所有电容，从而**刷新单行的时间和存取周期时间相同**

**集中刷新模式**下，每隔固定时间会逐行刷新全部电容

刷新周期是两次刷新完成的时间间隔

以`128*128`存储矩阵，存取周期 `0.5μs`，刷新时间`2ms` ，集中刷新为例

![img](https://pic2.zhimg.com/v2-5b19fd7a2131694c20611fe6c91b3f65_1440w.jpg)

2ms=2000μs=4000周期

刷新128行相当于进行128次读取操作，需要`128周期=128∗0.5μs=64μs`

则剩余的周期4000−128周期=3872周期=1936μs这段时间可以用于与CPU之间进行数据的读写

刷新消耗掉的时间中，存储体无法进行对外信息交换，称之为**死区**

死区时间占比为 128/4000=3.2% 称之为**死时间率**

在死区时间提交的I/O请求必须等待刷新完成

**分散刷新模式**下，每进行一次读/写后，就按需刷新一行电容

从而原 `0.5μs` 读写周期，变为`1μs`

![img](https://pic1.zhimg.com/v2-6878e06ac5e36f0b9f925f1e430a74b4_1440w.jpg)

以`128*128`存储矩阵为例，经过128次读写后，全部电容都被刷新了一次

分散刷新模式的特点是通过过渡的刷新，避免死区的出现，但也延长了存取周期

**异步刷新**是集中刷新和分散刷新的结合

![img](https://pic1.zhimg.com/v2-c94ca59277b80ba3d2c10841b0f573a8_1440w.jpg)

还是以`128*128`存储矩阵， `0.5μs`存取周期，为例

我们要求每隔`2ms`都会对整个矩阵完成一次刷新（刷新周期）

但并不是集中在一起完成，而将`128`行逐行刷新平分到`2ms`中，从而每`15.6μs`我们需要刷新一行

如果安排得当，我们可以在`15.6μs`中找到`0.5μs`的**窗口时间**，恰好CPU不访问该存储器（例如指令译码时），从而**死区不会暴露**，不影响CPU和存储器的信息交换

否则就需要强制在`15.6μs`的最后`0.5μs`进行一行刷新，死区暴露，如果CPU此时有I/O请求就必须等待刷新完成

**比较动态RAM和静态RAM**

![img](https://pic3.zhimg.com/v2-08b14f5cabe1c709f9ae6aaea93e0a32_1440w.jpg)

动态RAM可以分别传输行/列地址，地址线条数可以减为一半，从而减少DRAM的芯片引脚数，提高封装程度，提高集成度，扩大容量

而**静态RAM**通常需要发挥其**高速的优势**，因而**一般不会分别传输行/列地址**，封装度/集成度较低，容量不足

虽然我们经常需要刷新动态RAM，但静态RAM工作时，实际有三管需要一直保持导通，因而一直处于漏电状态，导致**静态RAM功耗高于动态RAM**

**SRAM造价较高容量低，无法大规模使用，通常用于做缓存(Cashe)**，发挥其高速优势

而**DRAM，造价低，容量大，通常用于计算机主存**，内存条就是DRAM

## 第五章 存储器(中)

### 1.**只读存储器（ROM）**

只读存储器中通常保存系统配置，系统文件一类**需要长期断电保存，不经常修改**的数据

早期的只读存储器在厂家生产时，直接写入数据，用户只能进行读出无法修改

后经不断发展，如今硬盘，U盘这些只读存储器在使用中能够进行反复电擦写

**掩膜ROM**

最早出现的掩膜ROM就是标准的

由厂家在生产时写入数据，用户只能进行读出，无法修改数据的只读存储器

掩膜ROM内部使用重合法构建二维存储矩阵的方式来存放数据，0/1由交叉点上MOS管的有无来确定，**交叉点上有MOS管表示1，无MOS管表示0**

自然行列MOS的有无，是由厂家生成芯片时确定的（硬件编码），用户无法做出更改

**PROM**

![img](https://picx.zhimg.com/v2-fd514b0bb6319ee9b36ea87a811eaee7_1440w.jpg)

在掩膜ROM的基础上，PROM通过设置熔丝，将数据写入的权力交给了用户

**用户可进行一次性破环性的数据写入**，0/1通过熔丝的熔断情况体现

熔丝熔断表示0，熔丝保留表示1

**EPROM**

![img](https://pic2.zhimg.com/v2-80b8edc95a4db28ae9a94b2ca7a095a7_1440w.jpg)

EPROM实现了多次可编程，通过D端的通联，形式浮动删来存储数据

如果需要再次编程，可通过**紫外线驱散浮动删**，擦除原有数据，重新写入即可

但EPROM的擦除需要独立的紫外线放射设备来完成

**EEPROM**

EEPROM实现了**电可擦写**（不需要特殊设备），能进行局部/全局的擦写操作

用户将EEPROM接入计算机中，可以读出数据，也可以直接由软件控制完成擦除并重新写入数据

**闪存FlashMemory**

高速电可擦写ROM存储器，已具备RAM的一些功能

我们使用的U盘就是闪存，可作为计算机的扩展存储器进行高速的数据读写

一些计算机直接使用闪存作为主存，就是使用固态硬盘

此外闪存还可以作为高速缓存（Cashe）

### 2.存储器与CPU的连接

CPU需要从存储器读取指令和数据，进行运算，并将运算结果保存在存储器中

因而我们需要将存储器和CPU进行正确的连接

**存储器容量扩展**

首先我们需要解决的问题就是存储器容量的扩展问题

相比CPU的地址线宽，数据线宽，无法直接使用单块存储芯片来满足

因此我们需要将多个存储芯片连接，**扩展地址范围满足CPU地址线宽要求，扩展存储字长适应CPU数据线宽要求**，从而构成一个存储(整)体

**位扩展（增加存储字长）**

位扩展的方法是将已满足地址宽度要求的存储芯片(存储整体)，统一接入地址总线，并根据芯片存储字长分配独立的数据线路即可

我们无需在意芯片连接地址总线/数据总线的顺序性，只需**将所有芯片接入统一的片选信号线，从而同时进行存取工作**

读写时，会根据数据线宽分配，在不同存储芯片同一地址位置处读出/写入数据

以`1K*4bit`存储芯片组成`1K*8bit`存储器为例，思路可表示为 `1K*8bit=1K*(4bit+4bit)`

![img](https://pica.zhimg.com/v2-1adf3990c630ab4de7facb280b488b76_1440w.jpg)

**字扩展（增加存储地址范围）**

字扩展的方法是将已满足存储字长的存储芯片(存储整体)，统一接入数据总线，**将一定数量的地址线路作为片选信号，从而划分地址总宽到每块存储芯片中**

以1K*8bit存储芯片组成2K*8bit存储器为例，我们需要使用1条地址线的0/1作为片选信号，选中对应的芯片，并将芯片地址线统一接入剩余的地址线即可

思路可表示为`2K*8bit=2*1K*8bit`

![img](https://pic2.zhimg.com/v2-18aeeccecb7e4ec44f95ddceff387b1d_1440w.jpg)

**字、位扩展**

更普遍的状况中，我们需要同时进行字、位扩展

思路是**先进行位扩展**，将存储芯片n个一组，满足数据宽度

**之后进行字扩展**，选取一定数量的地址线，作为选择线，划分地址宽度，**根据二进制状态映射为片选信号，选中相应的芯片组**

如图以8片 `1K*4bit`存储芯片 组成 `4K*8bit`存储器为例

![img](https://pic2.zhimg.com/v2-dbabcca3df0fa66970bd5a427529e3ef_1440w.jpg)

8片存储芯片两个一组，共四组，每组内分配数据线路，实现位扩展

再由两条地址线作为片选信号线，四种二进制状态 00 01 10 11 译码映射为片选信号，选中4组芯片中的1组工作，从而将地址总宽，划分到4组中

思路可表示为 `4K *8bit = 4 * 1K * (4bit+4bit)`

### 3.**存储器与CPU的连接**

在真正进行存储器与CPU连接时，情况往往比较复杂

除了上面提到的进行字扩展和位扩展，满足CPU给出的地址线宽度和数据线宽度外，我们还需解决以下问题：

1.读/写控制线的连接，注意RAM可读可写，而ROM只可读不可写

2.RAM与ROM的合理选择与混连，我们需要根据CPU地址范围及存储需求合理选择RAM/ROM芯片，通常保存系统程序，配置信息的地址范围使用ROM，用户程序范围使用RAM，不同芯片参数的选择，应让芯片数量尽可能的少，减少连接线路，使片选逻辑尽可能简单，且实际情况往往都需要我们混连RAM与ROM

3.片选线的连接，通常低位送入存储芯片作为寻址信号，高位参与片选信号的译码，我们要在RAM/ROM混连情况下合理分析高位地址信号的情况，选用相应的解码器，或是自行设计电路，完成片选信号的译码和连接

4.MREQ信号参与片选，MREQ是访存控制信号，低电平表示CPU要访问存储器，给出了存储器对应的地址，高电平表示CPU要访问I/O端口，给出的地址是I/O端口地址，因此我们需要MREQ信号参与片选信号的译码

5.存储芯片与CPU之间的时序，负载关系，芯片与CPU时序要能相互配合，且芯片数量不超过CPU的最大负载

**例1：**

CPU地址线宽16路，地址空间2K，数据线宽8路 (2K*8bit)

其中6000H到67FFH地址范围为系统程序区，6800到6BFH为用户程序区

我们写出对应的二进制地址码（从高位到低位），分析范围，选用芯片

![img](https://pic3.zhimg.com/v2-f1bf7d75955005089ee713170a6389de_1440w.jpg)

将低位对应的地址线接入芯片作为寻址信号，分析高位地址信号，选用译码器或设计电路，产生片选信号

这里选用138译码器，输入信号需要CBA三路，如图可选用A13-A11作为输入信号，查表得到对应Y4和Y5端输出可作为片选信号

![img](https://pic3.zhimg.com/v2-737deb0b0b2ab91fa8de23aece6bdaac_1440w.jpg)

最终线路如图

![img](https://pic4.zhimg.com/v2-6a681df0f951af417e5fd7e46e1f5313_1440w.jpg)

138译码器启用信号G1端为高电平，可接A14信号线，G2A与G2B为低电平，可接A15与MREQ信号（注意保证MREQ访存信号参与译码）

此外对于RAM空间，除了A13-A11满足101外还需A10信号为低电平，因此对138译码器Y5输出端与A10信号连接与非门，将输出信号作为最终片选信号

数据线ROM恰好满足宽度，连接线路只单向传输到数据线（只读），两片RAM需要位扩展满足宽度，因而需要对数据线进行独立分配，连接线路双向传输数据（可读可写）

WR读写控制信号只与RAM相连，ROM只读不写，因而编程端 PD/Program 接地

**例2：**

CPU地址线宽16路，地址空间2K，数据线宽8路 (2K*8bit)

要求最小地址4K位系统程序区，相邻8K为用户程序区

写出地址二进制码，分析范围，选用芯片

![img](https://pica.zhimg.com/v2-97ef6e7f79475eb994645c3810a3431e_1440w.jpg)

这里由于接邻最小4K的前4K地址与后4K高位不同，选用了两片4K*8bit RAM芯片，并进行字扩展

分析高位地址信号，确定片段信号

![img](https://picx.zhimg.com/v2-084fb8beedab5b00155ea2ef43f786a1_1440w.jpg)

最终接线如图

![img](https://picx.zhimg.com/v2-d8f39fe0195ef8b1cc5517961f60a2b9_1440w.jpg)

G1高电平直接电源，G2A G2B低电平接A15和MREQ

查表可得Y0 Y1 Y2端输出满足要求

### 4.存储器的校验

**存储器的校验**

事实上在现代计算机复杂的电路中，不论是RAM还是ROM，经常受到内部电路的信号干扰，或是外部的各种因素影响，导致触发器翻转，电容异常的充放电，导致存储信息发生一定的改变

因此我们需要对存储器中的信息，进行一定的校验，以防止读出数据错误，程序指令错误，保证计算机能够正常的运行

存储器校验在现代计算机中应用广泛，不止一些安全系统，面向个人的微型计算机也采用了校验技术

**接收方**会通过一定的机制，对收到的数据进行检错/纠错，以保证数据的准确

**合法代码集合**

要想知道读出数据是否正确，我们就需要规定一定的**合法代码集合**，以便在存储数据发生改变时知道数据出错(检错)，并进行矫正(纠错)

在存储信息出错的情况中，1位信息出错占90%以上

如图给出4组合法代码集合，及它们各自的检错纠错能力

![img](https://pic4.zhimg.com/v2-8733484479021fbb6455389510709357_1440w.jpg)

我们不难发现，合法代码集合的检错/纠错能力，与任意两和法代码之间的**二进制最小差异位数**有关，最小差异位数越多，检错/纠错能力越强

第一组最小差异为1位，不具有检错/纠错能力

第二组为3位，第三组位4位，第4组为5位，它们的检错/纠错能力依次增强

合法代码集合的二进制最小差异位数，又称之为**编码的最小距离**，应用合法代码集合进行检错/和纠错，在指令编码时就需要满足这一最小距离来编写（最短代码不能短于最小距离，其它代码时最小距离的整数倍）

编码最小距离与检错纠错能力有如下关系

![img](https://pic3.zhimg.com/v2-25a7110c032fb2f81b40e1ec22fa7bc4_1440w.jpg)

通常检错位数大于等于纠错位数

### 5.汉明码的组成

**奇偶检验与分组**

奇偶检验是另一种检错/纠错方法

奇偶校验就是加入一个校验位，使原代码一定范围内的1/0个数加校验位1/0，满足奇数或是偶数（通常采取偶校验）

例如8bit代码+1bit校验位，要求1个数为偶

![img](https://pic3.zhimg.com/v2-09ed7f67d90a199b095a14de367fe6de_1440w.jpg)



奇偶校验通常结合分组使用，简单的分组方法就是继续细分代码段，每段都加入一个校验位从而进行更细致的检错/纠错

![img](https://pic4.zhimg.com/v2-bdf2c6969847555f6c089cf6ae789505_1440w.png)



简单分组中，各分组间代码段不重叠，而更加复杂的非划分，重叠分组法中，会**利用重叠分组，在检错的同时准确定位出错的位置**

如图汉明码的非划分分组

![img](https://pica.zhimg.com/v2-893a66d36119f9025c407857d7917824_1440w.jpg)

P1组包括 1357

P2组包括 2367

P3组包括 4567

我们在2^i位置放校验码（**独立位放校验码**），将1-7共8bit数据按如图的重叠方式划分为3组，从而在检错的同时，根据重叠关系定位出错位置

校验是若满足奇偶约定，则输出0，不满足输出1，依次排列P3P2P1的检测位，若结果为000则没有差错，否则这**三个检测位组成的二进制位数就是出错的位置**

### 6.汉明码的编码规则

汉明码就是一种特殊的**编码规则**，依托于这种编码规则我们可以在奇偶校验的同时，定位出错的位置

许多其它类型的检测/纠错方法，都是在奇偶校验的基础上，制定了不同的编码规则

汉明码编码规则是根据位数的二进制表示中，第n位上是否为，来决定这位数是否要进入第n组，一位数据可以被同时划分进多组中

对于 00001 00010 这样的只有一位是1每组独有的位置，就成为检测位

任意两组，三组，n组都有唯一一个共有的位置

![img](https://pic4.zhimg.com/v2-7e28dce2c0717f7ccd8e23525f4cf17d_1440w.png)





以n表示汉明码的数据位，k表示检测位，则汉明码的编码规则可用公式表示为

$2^k \geq n + k + 1$

k位检测为，则有k组，相应的2^k种检测情况，要能映射指出n+k位数据在单位出错时的出错位置，再加一个无差错的情况

**例1：**

数据0101按偶校验配置汉明码

n=4 公式可得k最小为3，分三组，三个校验位

共3+4=7位传输数据，校验位为 1 2 4 值待定

数据位 3 5 6 7 对应数据 0101

P1组：1 3(0) 5(1) 7(1) 因此1配0

P2组：2 3(0) 6(1) 7(0) 因此2配1

P3组：4 5(1) 6(0) 7(1) 因此4配0

最终数据为：0100101

**例2：**

接收汉明码为 01001111 偶原则配置，求传送信息

共接收8位数据，公式可得此时为3组，对每组包含的数据进行**异或**操作

$P_{1} = 1 \oplus 3 \oplus 5 \oplus 7 = 0$ 

$P_{2} = 2 \oplus 3 \oplus 6 \oplus 7 = 1$ 

$P_{3} = 4 \oplus 5 \oplus 6 \oplus 7 = 1$

此时1组无措，2 3组有错，23组共有位置为6，因而第6位数据取反（纠错时只纠1位错）

或按P3P2P1排列校验码二进制110即为第6位

数据位3 5 6 7第6位取反，传递信息为0101

### 7.主存结构调整

前面提到过，CPU的发展遵从摩尔定律，且明显比存储器发展速度块

因而**CPU与同期存储器之间的速度存在很大的差异**，为了提高计算机系统整体的运行速度，我们必须对访存速度进行提升

自然最直接的方法是，精进存储器的设计和制作工艺，制造出更高速的存储器件

此外可以采用层次化的存储结构，设置**Cache高速缓存**来作为CPU和主存之间的中介

而本节中将介绍另一种提高访存速度的方法---**调整主存结构**

**单体多字系统**

假设CPU的数据线宽为16位，正常情况下针对每个地址应访问到16bit数据

单体多字系统是将主存中对每地址16bit的数据进行扩展，例如可扩展为64位（1字扩展为4字）

CPU每次读取时，会将4字数据一次性读入到寄存器中，再从寄存器中获取每字的指令/数据进行处理

从而通过扩大单次读取周期内获得的数据量，来提升访存速度

![img](https://pic4.zhimg.com/v2-89436daf0e00830898883be564ee8be7_1440w.jpg)

但这种主存结构也存在一定的问题

1.CPU在写入数据时，由于CPU数据字长小于存储字长，需要特殊的硬件逻辑来处理这种差异

2.程序运行时读取的指令/数据，并不完全是连续的存放在内存中，例如跳转指令，跳转执行范围大于4字的扩展范围时，就无法起到加速的效果，反而多读了无效的指令/数据

**多体并行系统**

之前讲到的多个 存储芯片/存储体 通过字扩展构成一整个存储体时，利用高位地址划分存储空间所用到的方法，就是**高位交叉顺序编址**的方法

![img](https://pic2.zhimg.com/v2-06a112a6559a8932a6f83ddcfe53376f_1440w.jpg)



高位交叉顺序编址的方法，实现简单，适合存储体的容量扩展，但并不利于提高CPU访存速，多个存储体都是独立接入总线与CPU相连接的，因而本身**具有并行访存的潜力**

但由于使用了高位交叉顺序编址，在程序运行时的指令/数据大都是**顺序存放在某一个**存储芯片/存储体中，导致CPU经常只**单独访问**某个存储芯片/存储体，**并没有将并行的潜力发挥出来**

对此的改进方法是采取**低位交叉各体轮流编址**，以低位作为体号(片选信号)，从而在地址上顺序存放的程序指令/数据，实际被交叉存放在了不同的存储芯片/存储体中

![img](https://picx.zhimg.com/v2-036170e9323aeb143e5458af771db1b5_1440w.jpg)

再结合之前提到的分离式通信的方法，可以在不改变存取周期的前提下，增加存储器的带宽

![img](https://pic4.zhimg.com/v2-18a9b2919f139d31c9e7c18b21197629_1440w.jpg)

在单体访存周期内CPU可连续对4个存储体发起访问请求

四体低位交叉存储器，为实现存取周期T，总线传输周期t下的**流水式存取**，应满足T=4t

![img](https://pic1.zhimg.com/v2-467fd11fcf96d94db712616633cf834c_1440w.jpg)

如图存取周期为T总线周期为t下的流水式访问

T+(4-1)t

连续读取4个字所需时间为T+(4-1)t

### 8.高性能存储芯片

如图三种高性能存储芯片

![img](https://pica.zhimg.com/v2-c1b4d9a5c7d6d8bebaeeb090f15929b6_1440w.jpg)

类型3中DRAM芯片内集成了一个由SRAM组成的Cache高速缓存，其**容量与芯片行容量相同**

CPU初次读取时，会在读取行列对应位置数据的同时，将这一行的数据加载到Cache中

由于程序指令/数据大都是顺序存储的，因而下一次读取大概率是读取与上一次同行不同列的数据

在下一次读取时若发现行地址与Cache加载的行数据地址相同即为“**缓存命中**”，可直接以列地址信号读出Cache中对应的数据

从而可以进行**猝发式读取**（第一次较慢之后若缓存命中可高速读取）

## 第六章 存储器(下)

### 1.高速缓冲存储器(Cache)

前面已经或多或少的提到了一些有关Cache的概念，Cache作为提高访存速度的一大手段，其应用对现代计算机速度的提升有很大的帮助

由于**同期CPU与存储器之间存在较大的速度差异**，为提高访存速度，我们可以在CPU和存储器之间架设一块容量小，但速度快的缓存，用于**中介速度差异**

![img](https://pic4.zhimg.com/v2-f4dda095cbe0a28e01dadd43a6343da9_1440w.jpg)

### 2.Cache工作原理

Cache的工作原理主要基于**程序访问的局部性原理**

程序访问的局部性原理，分为**时间局部性**和**空间局部性**

**时间局部性**：当前使用到的指令/数据，在未来有很大的概率会被再次使用

**空间局部性**：当前使用到的指令/数据，在未来有很大概率使用与之相邻的指令/数据

从而我们可以将当前使用到的指令/数据，以及与之相邻的指令/数据，这一定范围内的主存数据，读取到Cache中，期待CPU在未来正好使用到这些数据

按照，将一定范围内数据预读到高速缓存，这一目的，我们将主存和Cache按照**空间分块**的思路进行布置

![img](https://pic1.zhimg.com/v2-add2a27029bf999be393d7c40e812a26_1440w.jpg)

如图我们将主存的整个存储空间分为M块，每块内包含B个字，Cache的存储空间有C块，每块内也有B个字

M>>C，但M与C的最小单位即1块的容量大小是完全相同的，1块内B个字的空间划分也是完全相同的

在发生初次读取后，我们就可以将读取位置附近**D块容量范围(D<C)**的数据整体传送到Cache中

**Cache内地址对程序员来说是完全透明的**

从外特性来看，因为块内的空间划分也是相同的，我们**不需要生成Cache内地址**再映射主存地址，而是在预读后，**直接标记Cache中的地址为主存中对应的地址**

CPU下一次访问给出地址，**解码主存内块偏移地址**后，可直接询问与Cache标记地址是否相同，若相同则命中缓存，直接从Cache中获取数据即可

### 3.命中与未命中

主存M块与缓存C块在初次访问后，一定范围内包括初次访问位置和与之临近位置的数据，就被读入到了Cache中

主存块与缓存块的一部分建立了**对应关系**(部分主存块**调入**缓存)，并用**Cache中的标记记录**对应的**主存块偏移地址**

如果下一次CPU恰好访问了对应Cache中预读的数据，即为缓存命中，可直接从缓存中获取数据，速度比直接从主存中读取更快

但如果下一次CPU访问了的数据并不在Cache中，则缓存未命中，CPU仍需要低速的从主存中读取出数据，并且Cache中的数据会替换为与本次访问临近位置的数据

Cache的效能可以通过**缓存命中率**来描述，相同条件下命中率越高，对访存速度的提升越大

对于如何提高缓存命中率就已经超出了计组的范围，涉及到计算机体系/系统结构的内容

这里简单提一下两个相关因素：**容量**和**块长**

这里容量是指Cache容量与主存**容量的比例**，比值越大，Cache容量越接近主存容量，预读数据多，范围广，自然命中率越大

块长则是主存与Cache在空间分块时的单块长度配置，**块长需要做到合适**，

这里要强调的一点是，进行缓存调入(预读)时，并不是调入未命中读取位置与缓存块数量C相同的C'数量，而是**取D数量块(D<C)**，从而缓存中可以**保存多个(D/C个)**位置的邻近块数据

过长的块长导致缓存内块数量少，保存的位置少，调入时在一个位置读取过多的数据，CPU不一定都会用到反而产生浪费，过短的块长CPU仅几次访问后就超出了缓存范围需要重调缓存

一般块长一个存取周期内能从主存调出的信息长度，主存的多体交叉布置有关

![img](https://pic3.zhimg.com/v2-dad6a19667e6013015c43f4203b262be_1440w.jpg)

如图，CRAY_1主存16体低位交叉，每个存储体中保存1字数据，一个存取周期内能从主存中调出1存储体的1字长数据，从而缓存就恰是16字长，将16个低位交叉存储体中对应的1字都读入缓存中

好的,我来用数学公式的格式重新呈现：

### 4.Cache 主存系统的效率

访问效率e，是在Cache的影响下，CPU对主存进行访问的效能描述

效率e与命中率有关，它是访问Cache(缓存命中时)的访问时间，与平均访问时间的百分比

$e = \frac{访问Cache时间}{平均访问时间} * 100\%$

设Cache命中率为h，访问Cache时间为tc，访问主存时间为tm，则效率e的计算公式为

$e = \frac{t_c}{h*t_c+(1-h)*t_m} * 100\%$

上述计算公式适用于访问Cache与并行访问的情况，效率e的范围是[1,tc/tm]

若命中率为0，完全不命中仍可从主存中直接读取数据，访问效率取min值tc/tm

若命中率为1，绝对命中，访问效率取最大值100%，完全由Cache接管访存

但如果顺序访存，先访问Cache，不命中再访问主存，效率e的计算公式就变为：

$e = \frac{t_c}{h*t_c+(1-h)*(t_m+t_c)} * 100\% = \frac{t_c}{t_c+(1-h)*t_m} * 100\%$

e的范围变为$[1,\frac{t_c}{t_c+t_m}]$

### 5.CPU-Cache-主存 系统结构

![img](https://pica.zhimg.com/v2-4b1503c2c5d27ac7c79fc7c221a95a6a_1440w.jpg)

CPU与主存接入地址总线来传输访问地址

主存，Cache，CPU接入数据总线进行数据交换

Cache-主存之间有**片内直连通路**，进行缓存的调入(读取)

**映射机制**需要解决的是块地址与主存和Cache中存储位置的对应关系

此外主存块调入缓存时，也需要映射机制来进行位置的查找和分配，**决定主存块能够被缓入那些Cache块中**

Cache容量为C块，每次进行缓存调入时，会调入D块(D<C)主存数据，从而**Cache中能保存多个(D/C个)位置的临近数据**

若发生缓存未命中，则会**根据映射机制**，询问Cache中是否还有访问位置对应主存块**能够缓入**的块空间

不发生冲突，直接调入缓存，

若发生冲突则会采用一定的**牺牲机制**(替换机制)，牺牲**最不值得**继续保存的一个位置，替换调入未命中位置的块数据

### 6.对Cache的读写操作

**读操作**

在Cache的作用下，CPU访问主存时可检测Cache中是否已加载对应的数据，在缓存命中时直接从Cache中获取数据

缓存未命中时，CPU从主存获取数据并将获取位置附近的数据调入缓存

![img](https://pic4.zhimg.com/v2-2832bb9c13ca60f7ab653a1fdd8674c1_1440w.jpg)

**写操作**

对Cache的写操作发生在缓存调入后，CPU要对缓存位置的数据进行写入修改时，保证Cache和主存在外访问下写入数据的有效性

写操作有两种模式，**写直达法/写通过** 和 **写回法**

写直达法是在CPU对缓存位置进行写入时，**先将数据写入主存，之后主存将数据写入Cache**，写操作的时间就是访问主存的时间

这种方法保证了**Cache和主存数据始终一致**，但当CPU对某个缓存位置频繁写入时，会造成Cache和主存的频繁数据交换

写回法是CPU对缓存位置进行写入时，只写入Cache中，当Cache块判定牺牲，退出时，再将数据写回到主存，写操作的时间就是访问Cache的时间

这种方法**允许Cache和主存数据的不一致**，避免了Cache和主存频繁的数据交换，但在多处理器，多核心的情况下，每个处理器/核心都有自己私有的Cache时，无法保证各个Cache副本数据的一致性，需要特殊的处理（并行体系结构计算机）

### 7.Cache的改进

Cache也可以像计算机存储体系一样，通过增加级数构建**层次结构**

可分为片内(片载)Cache，片外Cache

单片内(片载)Cache可设置多级，目前许多处理器都至少拥有三级片载Cache

每个处理核心可以拥有自己的私有Cache，以及多核共用的Cache

片外可以设置大容量的Cache

通常Cache采用冯·诺伊曼结构的**统一缓存**，指令和数据统一存入一个缓存中

一种改进的思路是采用**分立缓存**，将指令和数据分别存入专用的Cache中，从而避免在流水的过程中造成资源冲突

![img](https://pica.zhimg.com/v2-8271789ab010473b720a9e2cd72212f8_1440w.png)

两种分立缓存芯片的例子

### 8.Cache-主存的映射方法

主存块在缓入Cache时，要根据一定的映射方法，有序的缓入一定范围内的Cache块中，**映射方法决定了主存的任意一块能够被缓入到Cache的哪些块中**

**从而在CPU访存时，根据映射方法快速查询是否命中缓存**

**直接映射**

直接映射方式的思想是一个主存块只对应唯一一个Cache块

直接映射是将M个主存块分为若干区，每区包含C块等同于Cache块数量

每区内第n个主存块，只能被存入Cache的第n块中（**区内块号对应Cache块编号**）

并在存入**将区号记录到标记**

从而地址被解码为三部分：区号，区内块号，块内字地址

在CPU访存时，会根据区内块号，查找相应**Cache块中所标记的区号与地址解码区号是否相同**，从而只对1个特性位置的Cache块进行1次标记与区号的判定，就能获知是否命中缓存

![img](https://pic3.zhimg.com/v2-0f517b71589954bb194bea21aa062b0a_1440w.jpg)



直接映射方式非常简单，容易实现，查找速度快，但缓存命中率不高，Cache调入时冲突概率高，Cache空间的应用效率不高

极端情况Cache中只调入了少量的块数据，存在大量空余位置，但每次调入时仍发生冲突替换

**全相联映射**

全相联映射的思想是一个主存块可以放在Cache中的任何一个块位置

从而只要Cache中还有空余位置，调入时就不会产生冲突

地址被解码为两部分：块号，块内字地址

CPU访存时，需要**遍历Cache的所有块，轮询标记**的块号与地址解码块号是否相同

未命中时进行替换，**又需要遍历所有块，查找空余位置，或进行牺牲判断**

![img](https://pic1.zhimg.com/v2-c53fc2fdc54d4b5a072af4f5c508d9b4_1440w.jpg)

全相联映射结合合理的牺牲机制，最大限度的利用了Cache的空间，避免了冲突的产生，有效提高了缓存的命中率

但由于需要进行复杂的遍历轮询，逻辑电路复杂，实现困难，访问Cache速度较慢

未对主存块进行分组，因而标记和比较器需要有足够长的位数

**组相联映射**

组相联映射是直接映射和全相联映射的结合，一个主存块可以放在一组缓存块中的任意一个位置

组相联映射首先对Cache进行分组，每组可包含2块，4块，8块不等（设有Q组）

根据Cache的分组数量，对主存进行分区，**每区包含的块数量等同于Cache的组数**（每区包含Q块）

在映射时，根据某一主存块在分区内的编号，可映射到相应的组内任何一块

可理解为相对于整个主存储器的块号j%Q=i，则第j块可映射到第i组中的任何一块

当CPU访存时，地址被解码为三部分：区号，区内块号(组号)，块内字地址

根据区内块号i，查找Cache第i组中记录的所有标记是否等于区号来确认是否命中缓存

![img](https://pic4.zhimg.com/v2-f5a57da9e8bd67007462989175d82041_1440w.jpg)

组相联映射电路结构比直接相连复杂，但比全相联映射简单的多，实现比较容易，查找速度较快，Cache命中率较高，是现代计算机Cache-主存普遍使用的一种映射方法

组相联映射电路结构比直接相连复杂，但比全相联映射简单的多，实现比较容易，查找速度较快，Cache命中率较高，**是现代计算机Cache-主存普遍使用的一种映射方法**

如果我们只将Cache分成1组，那么组相联映射就变为了全相联映射，如果Cache 1块1组，那么组相联映射就变为了直接相联映射

Cache-主存的映射方法在Cache的层次结构中，需要**根据与CPU的距离选择**

**最靠CPU的Cache层次，要求尽可能高速**，可采用直接相联映射，或路数较少的组相联(2路 4路)

中间层次的Cache，可采用2路 4路 8路组相联

**最远离CPU的Cache层次，对速度要求低，对Cache空间利用率要求较高**，可采用全相联

### 9.Cache的替换算法

替换算法是当为命中调入缓存发生冲突时，对已调入的缓存进行牺牲判断的逻辑/策略

**先进先出(FIFO)**

一种最简单的逻辑，认为发生冲突时，最早被调入的缓存是最不值得被保留的，因此我们可以记录调入缓存的时间戳，找到最早被调入的缓存块将其替换出

**最近最久未使用策略(LRU)**

事实上先进先出存在一个巨大的漏洞，可能最早被调入的缓存是我们经常用到的，具有很高价值的缓存

因此我们可以根据对缓存的命中访问来记录时间戳，发生冲突时，找到最近一段时间内最不常用的一块缓存替换出

这里Real Time Rending有关纹理贴图的章节，也有讲到关于纹理缓存替换的机制问题，同样提到了最近最久未使用策略

此外RTR还提到了，**最近最常使用策略(MRU)**

在一段时间内，在多帧进行大批量的访问时，由于调入缓存数量过多，以至于超出Cache(缓存容量)范围，并发生了抖动(Thrashing)，这种情况下LRU将会变为一种很不好的策略

为应对这种情况Camack提出了MRU策略，在LRU的基础上增加一个**交换检查**，如果发现抖动就切换到MRU策略，将最近保存的/最近命中的替换出（相当于是LRU的反逻辑）

直到检测不到交换为之，再切换回LRU策略

除了根据最近访问时间的策略外(R策略)，还有依据访问频率**LFU MFU**策略(F策略)

### 10.辅助存储器

**辅助存储器是指除计算机内存及CPU缓存以外的储存器**

用于长期保存计算机的程序/数据/文档/资料等等不经常被使用数据，一般断电后仍能保存数据

硬盘、U盘、光盘都是辅助存储器

辅助存储器的特点是不直接与CPU交换信息，需要将信息调入到主存(内存)中，CPU才能读取到指令/数据（应用程序启动时从硬盘加载到内存中才能运行）

### 11.磁表面存储器

磁表面存储器是最常用的一种辅助存储器，磁盘经常作为计算机硬盘

对磁表面存储器的描述主要包括以下5个技术指标

**记录密度**

记录密度描述磁盘表面存储二进制信息的密度，包含道密度和位密度

道密度是每单位径向长度上分布的磁道数量

位密度是每单位长度磁道上的二进制信息数量

磁盘盘面每个磁道都是同心圆，一定扇形范围内的圆弧构成一个扇区，越往外侧磁道的位密度越低

**存储容量**

描述磁盘存储二进制信息的容量，可以通过多种算法计算出容量

课本上给出的算法C=n*k*s 

n是盘面数量，k是磁道数量，s是平均每磁道保存的二进制信息量

**平均寻址时间**

从给出地址信息到磁盘输出数据的平均时间

根据磁盘的工作原理，平均寻址时间=寻道时间+等待时间

寻道时间是针对移动磁头的磁表面存储器，磁头寻找磁道的平均时间

等待时间是磁头来到指定磁道上方后，等待相应扇区旋转定位的时间

平均寻址时间是描述辅存速度的一种方法，磁表面存储器速度主要受制于寻址时间和磁头读写时间两部分

**数据传输速率**

单位时间能读出/写入的数据数量

数据传输率可通过位密度乘磁盘读/写时的平均线速度得到

**误码率**

读取时出错信息位数和总数的比值

### 12.磁记录的原理

写入时通过线圈电流方向的不同，决定磁头产生的磁场不同，从而对磁表面进行不同方向的磁化

![img](https://pic1.zhimg.com/v2-6af2beb462684abbc315416e35547c2e_1440w.jpg)

读出时，磁表面在磁头下方移动，根据运动速度，位密度规格，以及运动时磁表面磁化方向的不同切割磁感线在读现圈上产生的电势变化曲线，来确定保存的是0/1

![img](https://pic2.zhimg.com/v2-36ea434d118411f16b7dba32e736cf2b_1440w.jpg)

**硬盘存储器**

这里介绍的是**磁盘类型的硬盘**

尽管目前已经有相当一部分计算机，尤其是笔记本使用flash memory作为硬盘，就是所谓的固态硬盘

但磁盘仍以其**使用寿命长，数据不易损毁，可恢复性强**的特点，作为部分计算机的硬盘，或是长期保存数据的介质

**---------4.12.3.1 分类**

按照磁头可划分为**固定磁头**硬盘和**移动磁头**硬盘

固定磁头硬盘会在每一圈磁道上布置一个磁头，磁头数量多，在给出访存地址后，寻址时只需等待指定扇区旋转到位即可，因此读取速度块

移动磁头硬盘只有一个磁头，并通过机械臂/插车控制其径向移动，寻址时需要先移动磁头定位磁道，再等待扇区旋转到位，读取速度较慢

按照磁盘的更换行分为**可换盘**磁盘和**固定盘**磁盘

可换盘即可以更换盘片，磁盘存储器可看作保存数据的盘片和读写数据的控制&驱动器两部分

固定盘即盘片和外包的控制器&驱动器是一体结构的，通常固定盘对盘片的**工作环境要求苛刻，读写速度快**，一旦取出盘片破坏真空环境或占到灰尘后，就无法再续写数据（或必须使用专用的读取设备以极慢的速度读取）

**---------4.12.3.2 磁盘存储器的结构**

以控制器与主机总线相连，解码地址和处理数据的读出和写入，控制驱动器对盘片进行读/写操作

控制器可看作是主机和驱动器之间的**接口**，接收主机命令转换为对驱动器的控制命令，进行地址的解码转换和数据格式的转换

![img](https://pic4.zhimg.com/v2-3ce6ea733549f9330882ef68be693081_1440w.jpg)

移动磁头 磁盘驱动器结构如图

![img](https://pic2.zhimg.com/v2-da5447d102d533dd4b819290cfb10baf_1440w.jpg)

由主轴带动磁盘组旋转并使磁头悬浮在盘面上

磁盘控制器送来的磁道位置信息，通过音圈电机控制叉车镜像移动磁头定位磁道

音圈电机会将运行速度反馈给定位控制端，同时定位控制端会检测磁头当前所处的磁道位置，从而形成一个闭环控制系统，实现精确的磁道定位

**软盘存储器**

软盘也是一种磁表面存储器

软盘是个人微型计算机中最早出现的可移动存储介质，由一片磁盘+保护套组成，需要使用专用的软盘驱动器连接计算机进行读写

软盘质量轻巧，但相较于使用USB接口的U盘，容量过小，驱动器笨重，因而在U盘的出现和大规模应用后，已经淡出了人们的视线

不过有趣的是，时至今日，部分应用仍沿用软盘这一符号形象，作为保存图标

![img](https://pic2.zhimg.com/v2-e2dcd81381f030fe2f32c63500ffb3dd_1440w.jpg)

所以说...软盘可不是什么3D保存图标

对比硬盘与软盘

![img](https://pic1.zhimg.com/v2-18e64e028baf4a0a26d7ed9703f8cd54_1440w.jpg)

**光盘存储器**

光盘存储器采用**光存储技术**，通过激光进行写入和写出

第一代光存储技术，采用非磁性介质，**热作用烧刻**进行一次性写入，不可擦写，只能读出数据

第二代光存储技术，采用磁性介质(磁光材料)，通过**热磁效应**实现反复擦写

## 第七章 IO系统

I/O设备是能够被接入到计算机上运行的一切外部设备的总称

主要是为解决人机交互问题，为人类提供方便的输入设备，并将计算机的运算结果输出展示给人类，是计算机中种类最多，功能最多，结构最复杂，构成最多样的系统

I/O设备的丰富多样，是计算机能在各个领域大规模应用的基础。

### 1.概述

**I/O设备发展**

早期阶段，计算机种类和I/O设备数量有限，当时I/O设备与计算机采用专用线路分散连接，**程序查询方式**

CPU与I/O设备**串行工作**，要求I/O设备运行输入输出时，CPU必须同步运行相应的程序

随着计算机发展，外部设备越来越多，分散连接已不再适用于计算机的外部扩展

于是出现了**I/O接口，DMA控制器**，采用总线连接

CPU与I/O设备并行工作，出现了**中断**和**DMA**两种**传输控制方式**

I/O设备的输出输出，必须有运算器参与数据处理，原先由CPU直接作为运算器

但在之后的发展中为了提高效率，使CPU与I/O设备真正独立并行，**逐渐将I/O设备的输入输出处理从主机中独立出来**，出现了具有**通道**结构的I/O接口

通道是具有专用运算处理器功能的DMA控制器，具有自己的指令集，能够独立运行通道程序，它可以对I/O设备的输入输出数据进行处理，控制连接在通道上的I/O设备直接与主机进行数据交换

通道可以构成层次化的结构，通道下可以带并行工作的子通道，每个子通道可以连接多个设备控制器，每个设备控制器可以连接多个I/O设备

在通道之后，又出现了**I/O处理机**的理念，采用专用的微处理器连接控制I/O设备并完成数据处理

在一些大型计算机中可以直接使用与CPU相同的处理器作为I/O处理机，在空闲时可以作为主机处理器完成其它运算任务

**I/O系统的组成**

I/O系统分为**软件**和**硬件**两部分

**I/O软件**

分为**I/O指令**和**通道指令**

I/O指令是CPU指令的一部分，**程序员会将I/O指令编入应用程序**，从而在特定的时机接收I/O设备输入，或是将结果从I/O设备输出

通道是具有小型处理器的DMA控制器，拥有自己的指令集，自己的控制器，可以独立运行通道程序，控制I/O设备与主机直接进行数据交互

上层应用程序员在应用程序中编入的I/O指令都是**广义I/O指令**，

由**操作系统**，根据广义I/O指令，**使用通道指令编写通道程序**，将程序加载到内存或是通道自身的存储器中，启动通道运行程序，**来实现广义I/O指令**

**I/O硬件**

包含**输入输出设备**和**接口**

通道模式下，设备通过硬件接口连接设备控制器，控制器连接子通道，子通道连接通道，按此顺序接入层次化通道结构进行工作

**I/O设备与主机的联系方式**

CPU对I/O设备的访问指令包括操作码、指令码、设备码

![img](https://pic4.zhimg.com/v2-f27f6d5c3a40e7a2c8ccf94e8314adff_1440w.jpg)

操作码是一个标志，用于标识指令针对I/O设备进行控制

指令码指出了需要进行何种控制操作

设备码给出了I/O设备的编码、地址，或I/O设备中某个寄存器(端口)的地址

**编址方式**

CPU需要访问I/O设备时，需要在设备码部分给出I/O设备的地址，这就涉及到了I/O设备的编址方式

**统一编址**

统一编址是**将CPU地址总线宽度的一部分直接作为I/O设备的地址**

当CPU指令给出的地址码落入I/O设备的编址范围，则这次操作就针对相应的I/O设备执行

使用统一编址时，CPU可以直接使用取数、存数指令的指令码对I/O设备进行访问，**不需要单独的I/O指令**，CPU指令集相对简单

当CPU有足够的地址线宽时，不妨采取统一编址的模式

**不统一编址/单独编址**

对I/O设备的编址与内存地址不连读，独立于内存地址之外

此时就需要使用操作码标识**专用的I/O指令**对I/O设备进行访问

**设备选址**

在CPU运行指令时，需要对指令地址进行解码，并通过**设备选择电路**，选中相应的设备进行工作

**传送方式**

CPU与I/O设备之间的数据传送方式

之前已经进行了介绍，有串行和并行两种方式

**联络方式**

CPU与I/O接口通常都是异步并行的，这里的联络方式**针对I/O接口与I/O设备**

**立即响应方式**

对于结构简单，工作单一，状态数量少，的外部设备，可以采取直接响应的方式在接收到CPU控制信号后立即执行相应的工作，例如LED灯的亮灭

**异步工作方式**

对于结构复杂，需要对收发数据进行一定的转换，准备的设备可以采用异步工作方式

异步工作主要分为**并行**和**串行**两种方式，均采用应答信号来控制工作

**并行方式**中，I/O接口与I/O设之间通过复杂的类似总线结构相接，通过应答信号来控制工作进程

![img](https://pic3.zhimg.com/v2-2cd5bc5ca0e702b28d23f3a9b8bfc8ae_1440w.jpg)

**串行方式**中，在起始和终止时发送特定的命令信号，在中间传输需要的数据流

![img](https://pic2.zhimg.com/v2-045250b0f2ac451f376049a3ef3f71b9_1440w.jpg)

通常起始位是低电平，终止位是两个连续的高电平

**同步工作方式**

之前已经进行了介绍，需要定宽距的时标，统一工作进程

 **I/O设备与主机的连接方式**

早期采用**辐射(分散)连接**，这种方式能够适用于早期I/O设备种类数量少的情况

每台I/O设备都配有一套专用的控制线路和数据传输线路，不便于设备的增删，但有利于专用化的高速控制

后来I/O设备种类数量逐渐增多，**通过统一的I/O接口接入到计算机总线中**进行连接，有利于工业化的生产，便于增删设备，用户自由扩展

**I/O设备与主机信息传送的控制方式**

**程序查询方式**

最简单的CPU与I/O设备串行工作的控制方式

![img](https://pic2.zhimg.com/v2-c3365a61a09011e557fef286d7eab775_1440w.jpg)

以读取操作为例流程如图

CPU在现行程序中遇到I/O设备读取命令时，向I/O设备发送读指令

在接到读指令后，I/O设备需要一定时间进行自身的准备工作，在此期间CPU会不断的查询I/O设备是否准备完成（**原地踏步等待**），直到I/O设备完成准备前CPU不进行任何其它工作

准备完成后I/O设备将状态触发器标识置为准备完成，CPU与I/O设备进行数据传输，先将数据读入CPU的寄存器中，再由CPU写入到内存中（**CPU一拖二**）

**程序中断方式**

程序中断方式是对程序查询方式的一种改进，实现了CPU和I/O设备的部分并行工作

由于CPU与I/O设备运行速度不同，I/O设备往往需要较长的时间才能完成准备工作，导致CPU浪费许多时间等待



![img](https://pic4.zhimg.com/v2-39f958fd74f738a5ab918c92dccae7b3_1440w.jpg)

以读取操作为例程序中断方式流程如图

程序中断方式中将I/O设备的工作分为自身准备阶段和数据传输阶段

![img](https://pic1.zhimg.com/v2-88596d97bd5d26df4581677c7334fafa_1440w.jpg)

在CPU发出读/写命令后，I/O设备进入自身准备阶段时，CPU将继续执行其它工作（并行工作）

直到I/O设备准备完成，CPU将中断当前程序进程，跳转执行中断服务程序与I/O设备完成信息交换，之后再转回原来的程序进程

![img](https://pic3.zhimg.com/v2-7858fe4955b58b1227e04ae8fce7a7b0_1440w.jpg)

与程序查询方式相比，程序中断方式没有CPU原地踏步等待的现象，一定程度上提高了效率

但程序中断方式需要CPU记录相关的程序断点信息，才能完成中断跳转和转回，一次小数据量的读取，需要大量的指令处理中断操作

CPU在程序中断方式中，仍需要作为处理器，对I/O设备传输的数据进行处理（一拖二），并没有被真正的解放

**DMA方式**

DMA方式通过DMA处理器来完成对I/O设备传输数据的处理，实现了I/O设备与主存之间的直接联系，从而将CPU真正解放出来

![img](https://picx.zhimg.com/v2-4b0c00c91709a02c4345758894424695_1440w.jpg)

当程序运行过程中出现I/O操作时，CPU向DMA控制器发送启动I/O的信号并继续执行其它工作

I/O设备在DMA控制器的控制下完成准备工作，随后DMA控制器向CPU发送DMA请求

CPU接到请求后，会让出一个或数个存取周期，系统总线的占用权限（周期挪用），在此期间CPU不能使用系统总线，不能访问内存

DMA控制器在挪用的存取周期内，通过系统总线，控制I/O设备与主存完成信息交换

对于现代的CPU，即使让出了数个周期的系统总线权限，无法访问内存，仍能通过预取的指令和数据进行相应的工作（CPU工作可能不受影响）

**总结**

对比三种控制方式如图

![img](https://pic1.zhimg.com/v2-093788c531f4a1e3c6059ba11f45c436_1440w.jpg)

除了上述三种控制方式外，还有**通道方式**，**I/O处理机**方式，但超出了计组的范围，可以在计算机系统/体系结构的课程中了解

随着I/O系统的不断发展，I/O设备与主机之间的信息传输控制方式也在不断的革新，**I/O系统的自治力不断增强**，CPU逐渐从信息交换的处理器工作中被解放出来

