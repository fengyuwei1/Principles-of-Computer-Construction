# 计算机组成原理

## 第一章 计算机系统概论

### 1.计算机系统简介

现代计算机系统由硬件和软件两部分组成。

硬件包括计算机的实体部分，如主机、外设等。

软件是由具有各类特殊功能的信息组成，通过软件来发挥硬件的作用。

计算机的系统软件包括语言处理程序、操作系统、数学库、MPI等。而应用软件则是面向特定任务和目标的程序，如游戏、数据库管理系统等。

计算机的算力的单位是Flops(floating point operations per second)，即每秒可执行的浮点运算次数，Flops并不能反应许多对实际输出运算效率有影响的因素，因而计算机的实际Flops算力与理论峰值会有一段不小的差距

### 2.计算机系统的层次结构

```markdown
高级语言   虚拟机器M3
汇编语言   虚拟机器M2
操作系统   虚拟机器
机器语言   实际机器M1
微指令系统 微程序机器M0
```

**高级语言**（如C、Python）：为程序员提供易于理解和操作的编程环境。

**汇编语言**：与机器语言对应，但采用了易于理解的符号表示。

**操作系统**：为硬件提供抽象层次，控制硬件资源并管理程序运行。

**机器语言**：计算机能直接理解的指令集，依赖于特定硬件架构。

**微指令系统**：底层硬件通过微指令来执行高层的指令集。

计算机系统结构定义了计算机系统的软硬件的交界面，程序员所看到的计算机系统的属性。计算机组成设计人员的任务是实现计算机体系结构所体现出来的属性。

### 3.计算机的基本组成

冯诺依曼计算机是一种**存储程序结构**的计算机，数据和程序以**二进制方式**存放在计算机中。冯诺依曼计算机由五大部件组成，包括**运算器、控制器、存储器、输入设备和输出设备**。指令和数据以**同等地位**保存在存储器中，以二进制形式表示。指令由**操作码和地址码**构成，操作码指明操作类型，地址码指明操作数所在地址。冯诺依曼计算机的核心特点是存储程序，程序存放在存储器中。冯诺依曼计算机的硬件框图以运算器为中心，数据通过运算器进行流动。然而，以运算器为核心的冯诺依曼结构存在繁忙和瓶颈问题。

冯诺依曼计算机由以下五大部件组成：

- **运算器（ALU）**：执行算术和逻辑运算。
- **控制器（CU）**：控制计算机各个部件的工作流程。
- **存储器**：存储程序和数据。
- **输入设备**：用于向计算机提供外部数据（如键盘、鼠标）。
- **输出设备**：用于从计算机获取处理结果（如显示器、打印机）。

冯诺依曼计算机的关键是**存储程序**，即程序作为数据存储在计算机中，通过控制器逐步执行指令。这种结构具有灵活性，但也存在性能瓶颈，主要体现在**冯诺依曼瓶颈**（即CPU与内存之间的数据传输速度差异）。

冯诺依曼机工作方式的基本特点是按地址访问并顺序执行指令。

**1.程序指令和数据共用同一个存储器，进行等位存储，可以按地址寻访**

**2.指令和数据均以二进制表示**

**3.指令由操作码和地址码组成**，操作码反应了该指令的具体操作，地址码反映了操作需要应用到的操作数据所在的地址

**4.对程序指令进行存储和读取执行**

**5.以运算器为运行中心**

**哈佛结构**是计算机体系的另一种组织结构，它与冯·诺伊曼结构最大的区别是区分了程序指令和数据的存储器，分别使用两套地址/数据总线进行读写，**改进型哈佛结构**则对地址/数据总线进行了统一

### 4.对冯诺依曼机进行改进

首先，我们将运算器作为中心改进为以存储器为中心的机器，实现了输入输出设备和存储器之间的直接信息交换。

计算机系统的层次化结构，将计算机硬件划分为主机系统和IO系统，并进一步细化了CPU、主存和IO设备等模块。

CPU：运算器ALU,控制器CU

存储器：主存，辅存

主机：主存，CPU

IO系统：输入设备，输出设备，辅存

应对系统复杂性的三种方法：层次化、模块化和规则性。

层次化：将被设置的系统划分为多个模块或子模块

模块化：有明确定义的功能和接口

规则性：模块更容易被重用

### 5.计算机可计算性理论

可计算性：一类问题能否使用计算机去解决。

程序：运算的全部步骤

指令：每一个步骤

在计算机中，**指令**和**数据**都保存在存储器中，程序通过操作存储器中的数据来进行计算。

### 6.存储器的基本组成

存储器由存储单元、存储字和存储原件组成，可以按地址进行寻址。

存储器是核心结构，由多个存储单元构成，每个存储单元保存了若干个01的个数，称为存储字。

存储字长是存储单元当中二进制代码的位数。

存储单元：存储器中的最小单位，每个存储单元可以存储一定量的数据（如一个字节）。

存储字：存储单元中二进制代码的组合，是存储器的基本访问单位。

存储单元按地址进行寻址，寄存器MAR(存储器地址寄存器)保存了存储单元的地址或编号，MAR反映了存储单元的个数。MDR(存储器数据寄存器)保存了要送入CPU中的数据或要保存到存储体中的数据，MDR反映了存储字长。

存储原件：用于存储数据的物理器件，如动态随机存储器（DRAM）和静态随机存储器（SRAM）。

MAR和MDR是**存储器联系外部的窗口**，或称**接口寄存器**

### 7.运算器的结构

运算器的核心结构是累加器(ACC)，保存了其中的一个操作数和运算的结果。

运算器的核心是算术逻辑运算单元(ALU)，它完成加、减、乘、除和与非等运算。

运算器的输入数据保存在寄存器中，其中ACC和X寄存器用于保存运算的数据，MQ寄存器用于保存乘法运算的结果。

| 运算 | ACC         | MQ            | X      |
| :--- | :---------- | :------------ | :----- |
| 加法 | 被加数 和   |               | 加数   |
| 减法 | 被减数 差   |               | 减数   |
| 乘法 | 乘积高位    | 乘数 乘积低位 | 被乘数 |
| 除法 | 被除数 余数 | 商            | 除数   |

**乘法操作通过累加和移位实现**

基本原理：

1. **分解乘数**：将乘数（乘法运算中的第二个操作数）分解为二进制形式。例如，如果乘数是13，其二进制表示为1101。
2. **累加**：对于乘数的每一位，如果该位是1，则将被乘数（乘法运算中的第一个操作数）累加到一个临时的累加器中。如果该位是0，则不进行累加。
3. **移位**：在每次累加之后，将累加器中的结果左移一位。这相当于将当前的累加结果乘以2。这样做的原因是，每次移位都是在模拟乘以2的操作，因为乘数的每一位都代表了一个2的幂次。
4. **重复操作**：重复上述累加和移位操作，直到处理完乘数的所有位。
5. **得到结果**：完成所有位的处理后，累加器中的结果就是原始被乘数与乘数的乘积。

示例：

如果我们计算 5×13：

- 13的二进制是1101。
- 首先，5（被乘数）乘以1，结果是5，累加器现在是5。
- 然后，将累加器左移一位，变成10。
- 接着，5乘以1，累加，累加器保持15。
- 再次左移，变成30。
- 5乘以0，结果是30，累加器现在是30。
- 左移，变成60。
- 最后，5乘以1，累加到60，结果是65，累加器现在是65。

**除法操作通过减法和移位实现**

**基本原理：**

1. **分解除数**：将除数通过移位操作不断扩展，直到它接近或超过被除数。每次移位相当于乘以 2，类似于快速的二进制倍增。
2. **减法和移位**：通过从被除数中减去逐渐增加的除数的倍数，直到被除数变得小于除数。商的位数通过移位来构建。
3. **重复步骤**：直到被除数变为零或小于除数，最终商是移位和减法的累积结果。

**算法步骤：**

假设我们要计算 **a ÷ b**，其中 a 是被除数，b 是除数。

1. 准备

- 初始化商为 0。
- 初始时，将除数 b 移位，直到它接近被除数 a。

2. 操作

- 将除数 b 左移一位（即乘以 2）直到它大于等于被除数 a。
- 对于每一位，将这个扩展后的除数减去被除数，并将商的相应位设为 1。
- 对被除数进行减法操作，并记录商的当前位。
- 继续左移除数并重复此过程，直到被除数小于除数。

3. 完成

- 最终，商将通过这些步骤得到。

示例：**13 ÷ 5**

我们来详细看一个示例：**13 ÷ 5**。根据上述原理，我们用减法和移位来进行：

1. **初始状态**：
   - 被除数 **a = 13**，除数 **b = 5**，商 **q = 0**。
2. **扩展除数**：
   - 左移除数 b（5），得到 10（5 × 2）。
   - 由于 10 <= 13，继续进行。
3. **开始减法**：
   - 从 13 减去 10，得到 3。
   - 在商中，记录下当前位：商现在是 **1**。
4. **继续扩展**：
   - 再次左移除数 b，得到 20（10 × 2），但 20 > 3。
   - 因此，不进行减法操作。
5. **结束**：
   - 商最终是 2，余数是 3。

所以，**13 ÷ 5 = 2**，余数为 3。

运算器的结构可以根据机器的类型和功能进行灵活设置。

### 8.控制器的基本结构和功能

功能：

控制器的功能是解释指令，从取指到分析，到取操作数，到执行指令，一直到保存结果，这个过程都由控制器来控制完成。

1.解释指令

2.保证指令的按序执行

**完成一条指令的过程**

控制器的基本结构包括PC（程序计数器）和IR（指令寄存器）。执行一条指令的过程分为三个阶段：取指令、分析指令和执行指令。

1.取指令          PC(程序计数器)

2.分析指令      IR(指令寄存器)		 

3.执行指令      CU(控制单元)

PC存放当前欲执行指令的地址具有计数功能：(PC)+1 -> PC

IR存放当前欲执行的指令

取指令需要通过PC来获取指令的地址，然后将指令存入IR。分析指令将操作码部分送给控制单元进行分析。执行指令需要将地址码部分送给存储体，将数据取出并存入ACC寄存器。

**运算器，控制器，存储器构成了什么？**

计算机的硬件结构包括运算器、控制器和存储器，它们构成了计算机的主机。

**主机完成一条指令**

在主机上执行一条指令的过程包括取指令、分析指令和执行指令。

**程序在计算机上怎么运行**

通过输入设备将程序和数据保存到计算机的内存中，然后通过控制器将程序的首地址送入PC，启动机器开始执行程序

1.将程序通过输入设备送至计算机

2.程序首地址 ---> PC

3.启动程序运行

4.取指令 PC ---> MAR ---> M ---> MDR --->IR

5.分析指令 OP(IR) ---> CU

6.执行指令 Ad(IR) ---> MAR ---> M --->MDR --->ACC

7.打印结果

### 9.计算机硬件的主要技术指标

**1.机器子长**

CPU一次能处理数据的位数

与CPU中的寄存器位数有关，通常情况下，机器子长和CPU里面寄存器的位数是相等的

机器子长越长，机器性能越好

**2.运算速度**

1.主频：CPU时钟周期的频率，CPU的指令操作是在时钟信号控制下，每周期逐步完成的，因而主频在一定程度上能够反应CPU的运算速度

2.核数，每个核支持的线程数：CPU中每个核心都是能够独立执行某个程序/线程的处理器，高荷载下每个核心都能尽量保证自己的效率的稳定，但多核的优势也需要系统/程序进行对应的优化才能发挥作用，执行某些复杂的大型程序时，核心之间也需要相互配合才能完成工作，因而并不是多一个核心速度就能快一倍

主频与核心数只能说是硬件为了应对工作而进行的准备，因而并不能很好的反映实际的工作效率

3.吉普森法

吉普森法（Gibson's method）是一种计算机性能评价方法，它通过计算等效指令速度来衡量计算机的性能。等效指令速度是在指令执行速度的基础上，通过考虑每条指令的执行时间以及它们在全部操作中所占的百分比，来计算出一个等效的指令执行速度。这种方法能够更全面地反映计算机在不同程序下的性能表现。

等效指令速度的计算公式为：

$$
T = \sum_{i=0}^{n} (w_i \times t_i)
$$

其中：

其中：
- T 表示等效指令的执行时间，
- w_i 表示第 i 类指令在程序中所占的比例，
- t_i 表示第 i 类指令的执行时间，
- ∑ (sigma) 表示求和，
- i 从 1 到 n 变化，
- n 为指令类型的种类数。

通过计算各类指令的加权平均执行时间，可以得到一个等效的指令执行速度，用于衡量计算机的整体性能。

4.CPI 执行一条指令所需时钟周期数

5.MIPS 每秒执行百万条指令

6.FLOPS 每秒浮点运算次数

**3.存储容量**

存放二进制信息的总位数

主存容量

- 存储单元个数 × 存储字长
  - 例如，MAR（存储器地址寄存器）容量为 10 × 8 位 = 1 K × 8 位
  - MDR（存储器数据寄存器）容量为 16 × 32 位 = 64 K × 32 位
- 字节数
  - 2^13b=1 KB（1K = 2^10）
  - 2^21b=256 KB（1B = 2^3b）

辅存容量

- 字节数 80 GB

这里的“主存”通常指的是RAM（随机存取存储器），而“辅存”则通常指的是硬盘驱动器或其他类型的非易失性存储。存储单元个数指的是存储器中可以存储数据的单元数量，存储字长指的是每个存储单元可以存储的位数。字节数是衡量存储容量的单位，1字节（Byte）等于8位（bit），1千字节（KB）等于210210字节，即1024字节。

## 第二章 计算机的发展与应用

### 1.计算机发展的驱动力

计算机本质就是用于计算的机器，因而其发展的一大驱动力就是人类，从国防到公司团体再到个人，对实现高速运算需求的不断扩展

技术的发展也起到了很大的作用，主要是**硬件(电子技术)**的不断发展，和**计算机体系结构理论**的发展完善

其中硬件(电子技术)的发展对现代计算机的发展起到了决定性的作用，因而计算机的更新换代就是电子技术的更新换代

### 2.微处理器和微型计算机

微处理器是指一片高度集成化的电路，包含控制器，运算器，所构成的处理核心，也就是我们平时所说的CPU

微型计算机是指使用维处理作为处理核心，高度集成化的，面向个人用户，体积小，重量轻，价格低的计算机型，也就是我们平时所说的电脑

### 3.摩尔定律

摩尔定律是Interl公司创始人之一Gordon Moore所提出的，CPU发展过程中，新一代的CPU约每隔18-24个月就会发布，其包含的晶体管数量便会较上一代增加一倍，性能也会提升一倍，从而1美元能够购买到的算力每18-24个月便会增长一倍

然而随着晶体管的不断缩小，集成度不断增大，集成电路芯片已经逐步顶到了电介质传导速度和量子隧穿效应两大天花板，导致如今的发展较摩尔定律预测逐步放缓，逐渐达到集成电路这种构造模式的瓶颈，以至于停滞不前

CPU/微处理器芯片正期待着能有更先进的构造技术，打破集成电路的瓶颈，以迈向新世代

### 4.计算机软件的发展

计算机软件技术的发展主要是编程语言和系统软件的发展过程

早期的编程直接使用机器语言，对应硬件指令集进行编程，后来逐渐发展出汇编语言，相比机器语言更容易记忆，之后出现的面向过程，面向对象的高级语言使程序员不必在意底层的硬件实现，可以直接针对问题进行编码

系统软件是面向硬件编程，管理硬件资源，解决硬件问题，为上层软件提供/维护运行环境的一类软件，操作系统是系统软件的一类，是软件的底层。系统软件的应用使上层软件开发者，计算机的使用者不必在意底层的硬件工作。语言处理程序(汇编，编译，解释程序)，服务性程序（装配，调试，诊断，排错），数据库管理系统，网络软件也属于系统软件

现代软件的特点是，代码量大，制作成本昂贵，软件测试/质量检测流程复杂。软件的开发依赖多人协作编码完成，开发周期长

输入域测试，代码覆盖测试，路径覆盖测试，是软件测试的一些基本策略，但对于现代软件而言这些测试也需要消耗大量的人力物力，并且往往只针对某个单元进行全面覆盖，因而软件出现漏洞，出现bug，造成损失，只能尽量规避，无法完全避免